{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly\n",
    "from plotly.graph_objs import Scatter, Layout\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "import IPython.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_length = 50001\n",
    "time_per_sample = 0.01\n",
    "signal_time = np.linspace(num=sample_length,start = 0, stop = sample_length * time_per_sample )\n",
    "signal_amp = np.sin(signal_time*2*np.pi) + np.random.normal(size=sample_length)*0.02\n",
    "    #np.sin(2+signal_time*1.7*np.pi)*0.5 + \\\n",
    "    #np.sin(1+signal_time*2.2*np.pi) + \\\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "type": "scatter",
         "x": [
          0,
          0.010000199999999999,
          0.020000399999999998,
          0.030000599999999995,
          0.040000799999999996,
          0.050001,
          0.06000119999999999,
          0.07000139999999999,
          0.08000159999999999,
          0.09000179999999999,
          0.100002,
          0.1100022,
          0.12000239999999998,
          0.1300026,
          0.14000279999999998,
          0.150003,
          0.16000319999999998,
          0.17000339999999997,
          0.18000359999999999,
          0.19000379999999997,
          0.200004,
          0.21000419999999997,
          0.2200044,
          0.23000459999999998,
          0.24000479999999996,
          0.250005,
          0.2600052,
          0.27000539999999995,
          0.28000559999999997,
          0.2900058,
          0.300006,
          0.31000619999999995,
          0.32000639999999997,
          0.3300066,
          0.34000679999999994,
          0.35000699999999996,
          0.36000719999999997,
          0.3700074,
          0.38000759999999995,
          0.39000779999999996,
          0.400008,
          0.41000819999999993,
          0.42000839999999995,
          0.43000859999999996,
          0.4400088,
          0.45000899999999994,
          0.46000919999999995,
          0.47000939999999997,
          0.4800095999999999,
          0.49000979999999994,
          0.50001,
          0.5100102,
          0.5200104,
          0.5300106,
          0.5400107999999999,
          0.5500109999999999,
          0.5600111999999999,
          0.5700114,
          0.5800116,
          0.5900118,
          0.600012,
          0.6100121999999999,
          0.6200123999999999,
          0.6300125999999999,
          0.6400127999999999,
          0.650013,
          0.6600132,
          0.6700134,
          0.6800135999999999,
          0.6900137999999999,
          0.7000139999999999,
          0.7100141999999999,
          0.7200143999999999,
          0.7300146,
          0.7400148,
          0.7500149999999999,
          0.7600151999999999,
          0.7700153999999999,
          0.7800155999999999,
          0.7900157999999999,
          0.800016,
          0.8100162,
          0.8200163999999999,
          0.8300165999999999,
          0.8400167999999999,
          0.8500169999999999,
          0.8600171999999999,
          0.8700173999999999,
          0.8800176,
          0.8900177999999999,
          0.9000179999999999,
          0.9100181999999999,
          0.9200183999999999,
          0.9300185999999999,
          0.9400187999999999,
          0.950019,
          0.9600191999999999,
          0.9700193999999999,
          0.9800195999999999,
          0.9900197999999999
         ],
         "y": [
          -0.02700484858726314,
          0.06490365832486879,
          0.14852680055192014,
          0.2057330895044312,
          0.23485277900949691,
          0.3281898719526077,
          0.38297471154352436,
          0.4338028146455098,
          0.4918264324499686,
          0.572438132267164,
          0.5926173773095114,
          0.6356653942457963,
          0.685197412656871,
          0.7199523724913727,
          0.7834841079078649,
          0.7828242546134729,
          0.825509108832253,
          0.8732972692032207,
          0.9132046634931227,
          0.9216031875860037,
          0.9548528759320889,
          0.9833605676370147,
          0.9779927484439216,
          1.0391755580418334,
          1.0002277078044932,
          0.998136098982644,
          0.9964416232210854,
          0.9700560157459799,
          1.0042396072724675,
          0.9610473175385582,
          0.9506770898561536,
          0.9052008260980682,
          0.9069275874977415,
          0.8818346285696161,
          0.8224631598585225,
          0.8139835328973809,
          0.7731681005863925,
          0.7825306967920466,
          0.7080615204362402,
          0.6239663980698208,
          0.566193148760697,
          0.5533673733686303,
          0.4833669368792925,
          0.4164167784312603,
          0.3558734640782437,
          0.34378076966580107,
          0.2534180858687499,
          0.20198020487560575,
          0.12282849521470349,
          0.061288121938121616,
          -0.027872334053799103,
          -0.030234771097173742,
          -0.15814466339967614,
          -0.21423140417237516,
          -0.2489084744616875,
          -0.29528299854500634,
          -0.3346542462098758,
          -0.4479820049504373,
          -0.5027093850190364,
          -0.572772587574257,
          -0.6325310094599166,
          -0.6213533010958843,
          -0.661271002335925,
          -0.7446499279814082,
          -0.78111588766584,
          -0.7729425260077111,
          -0.8681718877102406,
          -0.8503317470239626,
          -0.9292715256186518,
          -0.9100693541499092,
          -0.9253932476026901,
          -0.9860666815734896,
          -0.9704256176357057,
          -0.9821035800468688,
          -0.9851085746598642,
          -0.9725982405857062,
          -0.9907920908956294,
          -0.9976846237630774,
          -0.9748826439236629,
          -1.00139937623753,
          -0.9338642976490449,
          -0.9186089617205011,
          -0.8930773314182392,
          -0.8748527676647395,
          -0.8332150103615,
          -0.8229933449393786,
          -0.7372109132554685,
          -0.7676200090399681,
          -0.6653767035338789,
          -0.6327471155202288,
          -0.5640465356911631,
          -0.5111983349590126,
          -0.48336785840190216,
          -0.4066782715514969,
          -0.36585722757564776,
          -0.328928267500224,
          -0.23022752536844218,
          -0.14711418220256914,
          -0.1441091327735691,
          -0.04009644154442231
         ]
        }
       ],
       "layout": {
        "title": ""
       }
      },
      "text/html": [
       "<div id=\"1547e947-71d2-43b8-a092-389738621a3a\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"1547e947-71d2-43b8-a092-389738621a3a\", [{\"type\": \"scatter\", \"x\": [0.0, 0.010000199999999999, 0.020000399999999998, 0.030000599999999995, 0.040000799999999996, 0.050001, 0.06000119999999999, 0.07000139999999999, 0.08000159999999999, 0.09000179999999999, 0.100002, 0.1100022, 0.12000239999999998, 0.1300026, 0.14000279999999998, 0.150003, 0.16000319999999998, 0.17000339999999997, 0.18000359999999999, 0.19000379999999997, 0.200004, 0.21000419999999997, 0.2200044, 0.23000459999999998, 0.24000479999999996, 0.250005, 0.2600052, 0.27000539999999995, 0.28000559999999997, 0.2900058, 0.300006, 0.31000619999999995, 0.32000639999999997, 0.3300066, 0.34000679999999994, 0.35000699999999996, 0.36000719999999997, 0.3700074, 0.38000759999999995, 0.39000779999999996, 0.400008, 0.41000819999999993, 0.42000839999999995, 0.43000859999999996, 0.4400088, 0.45000899999999994, 0.46000919999999995, 0.47000939999999997, 0.4800095999999999, 0.49000979999999994, 0.50001, 0.5100102, 0.5200104, 0.5300106, 0.5400107999999999, 0.5500109999999999, 0.5600111999999999, 0.5700114, 0.5800116, 0.5900118, 0.600012, 0.6100121999999999, 0.6200123999999999, 0.6300125999999999, 0.6400127999999999, 0.650013, 0.6600132, 0.6700134, 0.6800135999999999, 0.6900137999999999, 0.7000139999999999, 0.7100141999999999, 0.7200143999999999, 0.7300146, 0.7400148, 0.7500149999999999, 0.7600151999999999, 0.7700153999999999, 0.7800155999999999, 0.7900157999999999, 0.800016, 0.8100162, 0.8200163999999999, 0.8300165999999999, 0.8400167999999999, 0.8500169999999999, 0.8600171999999999, 0.8700173999999999, 0.8800176, 0.8900177999999999, 0.9000179999999999, 0.9100181999999999, 0.9200183999999999, 0.9300185999999999, 0.9400187999999999, 0.950019, 0.9600191999999999, 0.9700193999999999, 0.9800195999999999, 0.9900197999999999], \"y\": [-0.02700484858726314, 0.06490365832486879, 0.14852680055192014, 0.2057330895044312, 0.23485277900949691, 0.3281898719526077, 0.38297471154352436, 0.4338028146455098, 0.4918264324499686, 0.572438132267164, 0.5926173773095114, 0.6356653942457963, 0.685197412656871, 0.7199523724913727, 0.7834841079078649, 0.7828242546134729, 0.825509108832253, 0.8732972692032207, 0.9132046634931227, 0.9216031875860037, 0.9548528759320889, 0.9833605676370147, 0.9779927484439216, 1.0391755580418334, 1.0002277078044932, 0.998136098982644, 0.9964416232210854, 0.9700560157459799, 1.0042396072724675, 0.9610473175385582, 0.9506770898561536, 0.9052008260980682, 0.9069275874977415, 0.8818346285696161, 0.8224631598585225, 0.8139835328973809, 0.7731681005863925, 0.7825306967920466, 0.7080615204362402, 0.6239663980698208, 0.566193148760697, 0.5533673733686303, 0.4833669368792925, 0.4164167784312603, 0.3558734640782437, 0.34378076966580107, 0.2534180858687499, 0.20198020487560575, 0.12282849521470349, 0.061288121938121616, -0.027872334053799103, -0.030234771097173742, -0.15814466339967614, -0.21423140417237516, -0.2489084744616875, -0.29528299854500634, -0.3346542462098758, -0.4479820049504373, -0.5027093850190364, -0.572772587574257, -0.6325310094599166, -0.6213533010958843, -0.661271002335925, -0.7446499279814082, -0.78111588766584, -0.7729425260077111, -0.8681718877102406, -0.8503317470239626, -0.9292715256186518, -0.9100693541499092, -0.9253932476026901, -0.9860666815734896, -0.9704256176357057, -0.9821035800468688, -0.9851085746598642, -0.9725982405857062, -0.9907920908956294, -0.9976846237630774, -0.9748826439236629, -1.00139937623753, -0.9338642976490449, -0.9186089617205011, -0.8930773314182392, -0.8748527676647395, -0.8332150103615, -0.8229933449393786, -0.7372109132554685, -0.7676200090399681, -0.6653767035338789, -0.6327471155202288, -0.5640465356911631, -0.5111983349590126, -0.48336785840190216, -0.4066782715514969, -0.36585722757564776, -0.328928267500224, -0.23022752536844218, -0.14711418220256914, -0.1441091327735691, -0.04009644154442231]}], {\"title\": \"\"}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"1547e947-71d2-43b8-a092-389738621a3a\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"1547e947-71d2-43b8-a092-389738621a3a\", [{\"type\": \"scatter\", \"x\": [0.0, 0.010000199999999999, 0.020000399999999998, 0.030000599999999995, 0.040000799999999996, 0.050001, 0.06000119999999999, 0.07000139999999999, 0.08000159999999999, 0.09000179999999999, 0.100002, 0.1100022, 0.12000239999999998, 0.1300026, 0.14000279999999998, 0.150003, 0.16000319999999998, 0.17000339999999997, 0.18000359999999999, 0.19000379999999997, 0.200004, 0.21000419999999997, 0.2200044, 0.23000459999999998, 0.24000479999999996, 0.250005, 0.2600052, 0.27000539999999995, 0.28000559999999997, 0.2900058, 0.300006, 0.31000619999999995, 0.32000639999999997, 0.3300066, 0.34000679999999994, 0.35000699999999996, 0.36000719999999997, 0.3700074, 0.38000759999999995, 0.39000779999999996, 0.400008, 0.41000819999999993, 0.42000839999999995, 0.43000859999999996, 0.4400088, 0.45000899999999994, 0.46000919999999995, 0.47000939999999997, 0.4800095999999999, 0.49000979999999994, 0.50001, 0.5100102, 0.5200104, 0.5300106, 0.5400107999999999, 0.5500109999999999, 0.5600111999999999, 0.5700114, 0.5800116, 0.5900118, 0.600012, 0.6100121999999999, 0.6200123999999999, 0.6300125999999999, 0.6400127999999999, 0.650013, 0.6600132, 0.6700134, 0.6800135999999999, 0.6900137999999999, 0.7000139999999999, 0.7100141999999999, 0.7200143999999999, 0.7300146, 0.7400148, 0.7500149999999999, 0.7600151999999999, 0.7700153999999999, 0.7800155999999999, 0.7900157999999999, 0.800016, 0.8100162, 0.8200163999999999, 0.8300165999999999, 0.8400167999999999, 0.8500169999999999, 0.8600171999999999, 0.8700173999999999, 0.8800176, 0.8900177999999999, 0.9000179999999999, 0.9100181999999999, 0.9200183999999999, 0.9300185999999999, 0.9400187999999999, 0.950019, 0.9600191999999999, 0.9700193999999999, 0.9800195999999999, 0.9900197999999999], \"y\": [-0.02700484858726314, 0.06490365832486879, 0.14852680055192014, 0.2057330895044312, 0.23485277900949691, 0.3281898719526077, 0.38297471154352436, 0.4338028146455098, 0.4918264324499686, 0.572438132267164, 0.5926173773095114, 0.6356653942457963, 0.685197412656871, 0.7199523724913727, 0.7834841079078649, 0.7828242546134729, 0.825509108832253, 0.8732972692032207, 0.9132046634931227, 0.9216031875860037, 0.9548528759320889, 0.9833605676370147, 0.9779927484439216, 1.0391755580418334, 1.0002277078044932, 0.998136098982644, 0.9964416232210854, 0.9700560157459799, 1.0042396072724675, 0.9610473175385582, 0.9506770898561536, 0.9052008260980682, 0.9069275874977415, 0.8818346285696161, 0.8224631598585225, 0.8139835328973809, 0.7731681005863925, 0.7825306967920466, 0.7080615204362402, 0.6239663980698208, 0.566193148760697, 0.5533673733686303, 0.4833669368792925, 0.4164167784312603, 0.3558734640782437, 0.34378076966580107, 0.2534180858687499, 0.20198020487560575, 0.12282849521470349, 0.061288121938121616, -0.027872334053799103, -0.030234771097173742, -0.15814466339967614, -0.21423140417237516, -0.2489084744616875, -0.29528299854500634, -0.3346542462098758, -0.4479820049504373, -0.5027093850190364, -0.572772587574257, -0.6325310094599166, -0.6213533010958843, -0.661271002335925, -0.7446499279814082, -0.78111588766584, -0.7729425260077111, -0.8681718877102406, -0.8503317470239626, -0.9292715256186518, -0.9100693541499092, -0.9253932476026901, -0.9860666815734896, -0.9704256176357057, -0.9821035800468688, -0.9851085746598642, -0.9725982405857062, -0.9907920908956294, -0.9976846237630774, -0.9748826439236629, -1.00139937623753, -0.9338642976490449, -0.9186089617205011, -0.8930773314182392, -0.8748527676647395, -0.8332150103615, -0.8229933449393786, -0.7372109132554685, -0.7676200090399681, -0.6653767035338789, -0.6327471155202288, -0.5640465356911631, -0.5111983349590126, -0.48336785840190216, -0.4066782715514969, -0.36585722757564776, -0.328928267500224, -0.23022752536844218, -0.14711418220256914, -0.1441091327735691, -0.04009644154442231]}], {\"title\": \"\"}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s_i = 0\n",
    "e_i = s_i + 100\n",
    "x = plotly.offline.iplot({\n",
    "    \"data\": [Scatter(x=signal_time[s_i:e_i],y=signal_amp[s_i:e_i])],\n",
    "    \"layout\": Layout(title=\"\")\n",
    "    \n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 50\n",
    "prediction_length = 1\n",
    "input_feature_count = 1\n",
    "output_feature_count = 1\n",
    "batch_size = 128 #512\n",
    "hidden_count_per_layer = [16,16,16]\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, [None, sequence_length, input_feature_count], name = 'inputs')\n",
    "targets = tf.placeholder(tf.float32, [None, output_feature_count], name = 'targets')\n",
    "keep_prob = tf.placeholder(tf.float32, name = 'keep')\n",
    "learning_rate = tf.placeholder(tf.float32, name = 'learning_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = []\n",
    "\n",
    "\n",
    "for hidden_count in hidden_count_per_layer:\n",
    "    layer =  tf.nn.rnn_cell.LSTMCell(hidden_count, state_is_tuple=True)\n",
    "    layer_with_dropout = tf.nn.rnn_cell.DropoutWrapper(layer,\n",
    "                                          input_keep_prob=keep_prob,\n",
    "                                          output_keep_prob=1.0)\n",
    "    layers.append(layer)\n",
    "hidden_network = tf.nn.rnn_cell.MultiRNNCell(layers, state_is_tuple=True)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_state_tupel(state_tupel):\n",
    "    print(state_tupel)\n",
    "    if isinstance(state_tupel, tf.Tensor) or not hasattr(state_tupel, '__iter__'):\n",
    "        return state_tupel\n",
    "    else:\n",
    "        l = []\n",
    "        for item in state_tupel:\n",
    "            print(\"in = \",item)\n",
    "            v = pack_state_tupel(item)\n",
    "            print(\"po = \",v)\n",
    "            l.append(v)\n",
    "            \n",
    "        return tf.concat(1, l)\n",
    "        #return tf.concat(1, [pack_state_tupel(item) for item in state_tupel])\n",
    "\n",
    "def unpack_state_tupel(state_tensor, sizes):\n",
    "    def _unpack_state_tupel(state_tensor_, sizes_, offset_):\n",
    "        if isinstance(sizes_, tf.Tensor) or not hasattr(sizes_, '__iter__'): \n",
    "            return tf.reshape(state_tensor_[:, offset_ : offset_ + sizes_], (-1, sizes_)), offset_ + sizes_\n",
    "        else:\n",
    "            result = []\n",
    "            for size in sizes_:\n",
    "                s, offset_ = _unpack_state_tupel(state_tensor_, size, offset_)\n",
    "                result.append(s)\n",
    "            if isinstance(sizes_, tf.nn.rnn_cell.LSTMStateTuple):\n",
    "                return tf.nn.rnn_cell.LSTMStateTuple(*result), offset_\n",
    "            else:\n",
    "                return tuple(result), offset_\n",
    "    return _unpack_state_tupel(state_tensor, sizes, 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states in network (LSTMStateTuple(c=16, h=16), LSTMStateTuple(c=16, h=16), LSTMStateTuple(c=16, h=16))\n",
      "(LSTMStateTuple(c=<tf.Tensor 'MultiRNNCellZeroState_9/LSTMCellZeroState/zeros:0' shape=(128, 16) dtype=float32>, h=<tf.Tensor 'MultiRNNCellZeroState_9/LSTMCellZeroState/zeros_1:0' shape=(128, 16) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'MultiRNNCellZeroState_9/LSTMCellZeroState_1/zeros:0' shape=(128, 16) dtype=float32>, h=<tf.Tensor 'MultiRNNCellZeroState_9/LSTMCellZeroState_1/zeros_1:0' shape=(128, 16) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'MultiRNNCellZeroState_9/LSTMCellZeroState_2/zeros:0' shape=(128, 16) dtype=float32>, h=<tf.Tensor 'MultiRNNCellZeroState_9/LSTMCellZeroState_2/zeros_1:0' shape=(128, 16) dtype=float32>))\n",
      "in =  LSTMStateTuple(c=<tf.Tensor 'MultiRNNCellZeroState_9/LSTMCellZeroState/zeros:0' shape=(128, 16) dtype=float32>, h=<tf.Tensor 'MultiRNNCellZeroState_9/LSTMCellZeroState/zeros_1:0' shape=(128, 16) dtype=float32>)\n",
      "LSTMStateTuple(c=<tf.Tensor 'MultiRNNCellZeroState_9/LSTMCellZeroState/zeros:0' shape=(128, 16) dtype=float32>, h=<tf.Tensor 'MultiRNNCellZeroState_9/LSTMCellZeroState/zeros_1:0' shape=(128, 16) dtype=float32>)\n",
      "in =  Tensor(\"MultiRNNCellZeroState_9/LSTMCellZeroState/zeros:0\", shape=(128, 16), dtype=float32)\n",
      "Tensor(\"MultiRNNCellZeroState_9/LSTMCellZeroState/zeros:0\", shape=(128, 16), dtype=float32)\n",
      "po =  Tensor(\"MultiRNNCellZeroState_9/LSTMCellZeroState/zeros:0\", shape=(128, 16), dtype=float32)\n",
      "in =  Tensor(\"MultiRNNCellZeroState_9/LSTMCellZeroState/zeros_1:0\", shape=(128, 16), dtype=float32)\n",
      "Tensor(\"MultiRNNCellZeroState_9/LSTMCellZeroState/zeros_1:0\", shape=(128, 16), dtype=float32)\n",
      "po =  Tensor(\"MultiRNNCellZeroState_9/LSTMCellZeroState/zeros_1:0\", shape=(128, 16), dtype=float32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected int32, got list containing Tensors of type '_Message' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-3008a2e4c3ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"states in network\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mzero_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_state_tupel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder_with_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"initial_state\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#state = unpack_state_tupel(self.input_state, rnn.state_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-886a3be73edc>\u001b[0m in \u001b[0;36mpack_state_tupel\u001b[0;34m(state_tupel)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate_tupel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"in = \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_state_tupel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"po = \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-886a3be73edc>\u001b[0m in \u001b[0;36mpack_state_tupel\u001b[0;34m(state_tupel)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;31m#return tf.concat(1, [pack_state_tupel(item) for item in state_tupel])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1094\u001b[0m       ops.convert_to_tensor(\n\u001b[1;32m   1095\u001b[0m           \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"concat_dim\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m           \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m               tensor_shape.scalar())\n\u001b[1;32m   1098\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    227\u001b[0m                                          as_ref=False):\n\u001b[1;32m    228\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    206\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m    207\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 208\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    209\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    381\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m       \u001b[0m_AssertCompatible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m       \u001b[0;31m# check to them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m_AssertCompatible\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m       raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n\u001b[0;32m--> 303\u001b[0;31m                       (dtype.name, repr(mismatch), type(mismatch).__name__))\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected int32, got list containing Tensors of type '_Message' instead."
     ]
    }
   ],
   "source": [
    "print(\"states in network\", hidden_network.state_size)\n",
    "\n",
    "zero_state = pack_state_tupel(hidden_network.zero_state(batch_size, tf.float32))\n",
    "initial_state = tf.placeholder_with_default(zero_state, None, name = \"initial_state\")\n",
    "#state = unpack_state_tupel(self.input_state, rnn.state_size)\n",
    "\n",
    "#zero_state = pack_state_tuple(hidden_network.zero_state(batch_size, tf.float32))\n",
    "#initial_state = tf.placeholder_with_default(\n",
    "#    zero_state, \n",
    "#    (sz,1), \n",
    "#    name=\"initial_state\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff 0.0\n"
     ]
    }
   ],
   "source": [
    "# Test to check that the pack and unpack functions are eachothers inverse\n",
    "\n",
    "#copy of the input (packed) shape (x,1)\n",
    "initial_copy = tf.slice(initial_state,(0,0),(sz,1))\n",
    "\n",
    "#unpack into (LSTMTuple(),LSTMTuple(),....)\n",
    "unpacked = unpack_state_tuple(hidden_network,batch_size,initial_copy)\n",
    "rnn_tuple_state = unpacked\n",
    "#repack into vector (x,1)\n",
    "packed_again = pack_state_tuple(unpacked)\n",
    "\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    #v_outputs, v_state = sess.run([outputs,state], feed_dict={inputs: batch_inputs, targets: batch_targets})\n",
    "    cp = sess.run(initial_copy,  feed_dict={}) #initial_state: initial_state_input})\n",
    "    #cp[0] = 1\n",
    "    cp[:,0] = np.linspace(start=0,stop=cp.shape[0],num=cp.shape[0])\n",
    "    \n",
    "    cp,up,cp2 = sess.run([initial_copy,unpacked,packed_again],  feed_dict={initial_state: cp}) #initial_state: initial_state_input})\n",
    "    #print(\"cp\",cp.shape,cp)\n",
    "    #print(\"up\",unpacked,up)\n",
    "    #print(\"cp2\",packed_again,cp2)\n",
    "    #print(\"up2\",unpacked_again,up2)\n",
    "    diff = cp - cp2\n",
    "    print(\"diff\",np.sum(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs  (?, 50, 1)\n",
      "outputs before transpose (128, 50, 16)\n",
      "outputs after transpose (50, 128, 16)\n",
      "last output (128, 16)\n",
      "prediction (128, 1)\n",
      "targets (?, 1)\n"
     ]
    }
   ],
   "source": [
    "#out_weights=tf.Variable(tf.random_normal([hidden_count_per_layer[-1],output_feature_count]))\n",
    "#out_bias=tf.Variable(tf.random_normal([output_feature_count]))\n",
    "print(\"inputs \",inputs.shape)\n",
    "outputs, state = tf.nn.dynamic_rnn(hidden_network, inputs, dtype=tf.float32, initial_state=rnn_tuple_state, )\n",
    "state_packed = pack_state_tuple(state)\n",
    "print(\"outputs before transpose\", outputs.shape)\n",
    "outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "print(\"outputs after transpose\", outputs.shape)\n",
    "last_output = tf.gather(outputs, int(outputs.get_shape()[0]) - 1)\n",
    "print(\"last output\", last_output.shape)\n",
    "                                   \n",
    "#out_size = target.get_shape()[2].value\n",
    "predictions = tf.contrib.layers.fully_connected(last_output, output_feature_count, activation_fn=None)\n",
    "print(\"prediction\", predictions.shape)\n",
    "print(\"targets\", targets.shape)\n",
    "#prediction = tf.nn.softmax(logit)\n",
    "#loss = tf.losses.softmax_cross_entropy(target, logit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_sum(tf.squared_difference(predictions, targets))\n",
    "\n",
    "#optimization\n",
    "opt=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size 49949\n",
      "29971 Examples (234 batches) in train set\n",
      "9989 Examples (78 batches) in dev set\n",
      "9989 Examples (78 batches) in test set\n"
     ]
    }
   ],
   "source": [
    "start_indices = np.linspace(\n",
    "    0,\n",
    "    sample_length-sequence_length-prediction_length-1,\n",
    "    sample_length-sequence_length-prediction_length-1, dtype= np.int32)\n",
    "\n",
    "dev_size_perc = 0.20\n",
    "test_size_perc = 0.20\n",
    "\n",
    "dev_size = int(np.floor(start_indices.shape[0] * dev_size_perc))\n",
    "test_size  = int(np.floor(start_indices.shape[0] * test_size_perc))\n",
    "train_size = start_indices.shape[0] - test_size - dev_size\n",
    "train_batch_count = int(np.floor(train_size / batch_size))\n",
    "dev_batch_count = int(np.floor(dev_size / batch_size))\n",
    "test_batch_count = int(np.floor(test_size / batch_size))\n",
    "\n",
    "print(\"dataset size %d\" %(start_indices.shape[0]))\n",
    "print(\"%d Examples (%d batches) in train set\" %(train_size, train_batch_count))\n",
    "print(\"%d Examples (%d batches) in dev set\" %(dev_size,dev_batch_count))\n",
    "print(\"%d Examples (%d batches) in test set\" %(test_size,test_batch_count))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 50, 1) (128, 1)\n",
      "(50, 1)\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle (start_indices)\n",
    "train_indices = start_indices[0:int(train_size)]\n",
    "dev_indices= start_indices[int(train_size):int(train_size+dev_size)]\n",
    "test_indices = start_indices[int(train_size+dev_size):int(train_size+dev_size+test_size)]\n",
    "\n",
    "def get_batch(batch_index, indexes, size=batch_size):\n",
    "    batch_start_indexes = indexes[batch_index*size:batch_index*size+size]\n",
    "    batch_inputs = np.zeros((size,sequence_length, input_feature_count))\n",
    "    batch_targets = np.zeros((size,prediction_length))\n",
    "    for i in range(size):\n",
    "        se = batch_start_indexes[i]\n",
    "        part = signal_amp[se:se+sequence_length]\n",
    "        batch_inputs[i,0:sequence_length,0] = part\n",
    "        batch_targets[i,0] = signal_amp[se+sequence_length+1]\n",
    "\n",
    "    return batch_inputs,batch_targets\n",
    "\n",
    "batch_inputs,batch_targets = get_batch(train_batch_count-1,train_indices)\n",
    "print(batch_inputs.shape,batch_targets.shape)\n",
    "\n",
    "example_inputs = batch_inputs[0,:,:]\n",
    "example_targets =  batch_targets[0,:]\n",
    "print(example_inputs.shape)\n",
    "#b_i = 1\n",
    "#b_s = batch_inputs[b_i,0:sequence_length,0]\n",
    "#plotly.offline.iplot({\n",
    "#    \"data\": [Scatter(y=b_s)],\n",
    "#    \"layout\": Layout(title=\"\")\n",
    "#})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle (start_indices)\n",
    "train_indices = start_indices[0:int(train_size)]\n",
    "dev_indices= start_indices[int(train_size):int(train_size+dev_size)]\n",
    "test_indices = start_indices[int(train_size+dev_size):int(train_size+dev_size+test_size)]\n",
    "\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    np.random.shuffle (train_indices)\n",
    "    \n",
    "    batch_inputs,batch_targets = get_batch(0, train_indices)\n",
    "    print(\"batch input shape\", batch_inputs.shape)\n",
    "    #v_outputs, v_state = sess.run([outputs,state], feed_dict={inputs: batch_inputs, targets: batch_targets})\n",
    "    v_predictions, v_state, v_state_packed = sess.run([predictions,state, state_packed], \n",
    "                                      feed_dict={\n",
    "                                          inputs: batch_inputs, \n",
    "                                          targets: batch_targets\n",
    "                                      })\n",
    "    print(v_predictions.shape)\n",
    "    print(v_predictions[0],batch_targets[0])\n",
    "    for i in range(0,120):\n",
    "        v_predictions, v_outputs, v_state, v_state_packed, v_loss, v_opt = sess.run(\n",
    "            [predictions, outputs, state, state_packed, loss, opt], \n",
    "            feed_dict={\n",
    "                learning_rate: 0.02, \n",
    "                inputs: batch_inputs, \n",
    "                targets: batch_targets,\n",
    "                initial_state: v_state_packed\n",
    "            }) #})\n",
    "        print(v_loss,v_predictions[0],batch_targets[0])\n",
    " \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dev results batch 0, loss 64.349\n",
      "  Dev results batch 1, loss 64.1024\n",
      "  Dev results batch 2, loss 60.566\n",
      "  Dev results batch 3, loss 62.7298\n",
      "  Dev results batch 4, loss 60.85\n",
      "  Dev results batch 5, loss 58.9895\n",
      "  Dev results batch 6, loss 57.6051\n",
      "  Dev results batch 7, loss 70.635\n",
      "  Dev results batch 8, loss 63.5203\n",
      "  Dev results batch 9, loss 59.1915\n",
      "  Dev results batch 10, loss 62.316\n",
      "  Dev results batch 11, loss 68.2039\n",
      "  Dev results batch 12, loss 65.3623\n",
      "  Dev results batch 13, loss 57.5328\n",
      "  Dev results batch 14, loss 57.3198\n",
      "  Dev results batch 15, loss 61.9743\n",
      "  Dev results batch 16, loss 59.1721\n",
      "  Dev results batch 17, loss 66.7652\n",
      "  Dev results batch 18, loss 61.991\n",
      "  Dev results batch 19, loss 62.4706\n",
      "  Dev results batch 20, loss 66.4418\n",
      "  Dev results batch 21, loss 63.6695\n",
      "  Dev results batch 22, loss 61.8375\n",
      "  Dev results batch 23, loss 55.5109\n",
      "  Dev results batch 24, loss 59.9885\n",
      "  Dev results batch 25, loss 62.4615\n",
      "  Dev results batch 26, loss 57.8135\n",
      "  Dev results batch 27, loss 57.9281\n",
      "  Dev results batch 28, loss 57.107\n",
      "  Dev results batch 29, loss 61.9578\n",
      "  Dev results batch 30, loss 59.2098\n",
      "  Dev results batch 31, loss 61.0306\n",
      "  Dev results batch 32, loss 59.5636\n",
      "  Dev results batch 33, loss 63.0297\n",
      "  Dev results batch 34, loss 58.7174\n",
      "  Dev results batch 35, loss 56.4157\n",
      "  Dev results batch 36, loss 58.2722\n",
      "  Dev results batch 37, loss 63.9115\n",
      "  Dev results batch 38, loss 68.2839\n",
      "  Dev results batch 39, loss 62.2915\n",
      "  Dev results batch 40, loss 69.1152\n",
      "  Dev results batch 41, loss 62.8164\n",
      "  Dev results batch 42, loss 67.2987\n",
      "  Dev results batch 43, loss 62.1967\n",
      "  Dev results batch 44, loss 66.3562\n",
      "  Dev results batch 45, loss 58.8808\n",
      "  Dev results batch 46, loss 65.9019\n",
      "  Dev results batch 47, loss 62.6136\n",
      "  Dev results batch 48, loss 65.2641\n",
      "  Dev results batch 49, loss 70.2313\n",
      "  Dev results batch 50, loss 63.3378\n",
      "  Dev results batch 51, loss 57.5792\n",
      "  Dev results batch 52, loss 66.3019\n",
      "  Dev results batch 53, loss 62.6882\n",
      "  Dev results batch 54, loss 62.6103\n",
      "  Dev results batch 55, loss 61.1733\n",
      "  Dev results batch 56, loss 56.2863\n",
      "  Dev results batch 57, loss 66.5376\n",
      "  Dev results batch 58, loss 61.8074\n",
      "  Dev results batch 59, loss 67.8467\n",
      "  Dev results batch 60, loss 59.986\n",
      "  Dev results batch 61, loss 60.6352\n",
      "  Dev results batch 62, loss 57.6605\n",
      "  Dev results batch 63, loss 67.285\n",
      "  Dev results batch 64, loss 64.6129\n",
      "  Dev results batch 65, loss 58.8664\n",
      "  Dev results batch 66, loss 56.632\n",
      "  Dev results batch 67, loss 63.3064\n",
      "  Dev results batch 68, loss 62.7502\n",
      "  Dev results batch 69, loss 68.0828\n",
      "  Dev results batch 70, loss 57.8792\n",
      "  Dev results batch 71, loss 63.6825\n",
      "  Dev results batch 72, loss 60.1203\n",
      "  Dev results batch 73, loss 56.9905\n",
      "  Dev results batch 74, loss 55.5549\n",
      "  Dev results batch 75, loss 63.0625\n",
      "  Dev results batch 76, loss 56.5972\n",
      "  Dev results batch 77, loss 73.1539\n",
      "Dev results epoch start, loss 0.485012531806\n",
      "  Train results batch 0, loss 55.6637\n",
      "  Train results batch 1, loss 65.2996\n",
      "  Train results batch 2, loss 63.474\n",
      "  Train results batch 3, loss 57.6958\n",
      "  Train results batch 4, loss 54.0508\n",
      "  Train results batch 5, loss 46.7456\n",
      "  Train results batch 6, loss 46.897\n",
      "  Train results batch 7, loss 40.6577\n",
      "  Train results batch 8, loss 41.291\n",
      "  Train results batch 9, loss 36.8565\n",
      "  Train results batch 10, loss 31.6639\n",
      "  Train results batch 11, loss 31.6156\n",
      "  Train results batch 12, loss 22.7341\n",
      "  Train results batch 13, loss 17.0538\n",
      "  Train results batch 14, loss 11.9438\n",
      "  Train results batch 15, loss 6.48472\n",
      "  Train results batch 16, loss 2.82027\n",
      "  Train results batch 17, loss 0.879285\n",
      "  Train results batch 18, loss 1.09758\n",
      "  Train results batch 19, loss 2.61162\n",
      "  Train results batch 20, loss 3.49902\n",
      "  Train results batch 21, loss 4.34765\n",
      "  Train results batch 22, loss 4.96743\n",
      "  Train results batch 23, loss 5.35654\n",
      "  Train results batch 24, loss 4.67122\n",
      "  Train results batch 25, loss 3.24238\n",
      "  Train results batch 26, loss 2.36187\n",
      "  Train results batch 27, loss 1.23886\n",
      "  Train results batch 28, loss 0.787301\n",
      "  Train results batch 29, loss 0.618259\n",
      "  Train results batch 30, loss 0.670158\n",
      "  Train results batch 31, loss 0.670485\n",
      "  Train results batch 32, loss 0.780542\n",
      "  Train results batch 33, loss 0.837205\n",
      "  Train results batch 34, loss 0.990725\n",
      "  Train results batch 35, loss 1.15233\n",
      "  Train results batch 36, loss 1.25634\n",
      "  Train results batch 37, loss 0.956385\n",
      "  Train results batch 38, loss 1.08498\n",
      "  Train results batch 39, loss 0.763236\n",
      "  Train results batch 40, loss 0.60609\n",
      "  Train results batch 41, loss 0.457645\n",
      "  Train results batch 42, loss 0.350553\n",
      "  Train results batch 43, loss 0.376995\n",
      "  Train results batch 44, loss 0.267217\n",
      "  Train results batch 45, loss 0.222295\n",
      "  Train results batch 46, loss 0.210605\n",
      "  Train results batch 47, loss 0.210589\n",
      "  Train results batch 48, loss 0.274617\n",
      "  Train results batch 49, loss 0.327897\n",
      "  Train results batch 50, loss 0.265109\n",
      "  Train results batch 51, loss 0.31818\n",
      "  Train results batch 52, loss 0.280438\n",
      "  Train results batch 53, loss 0.243498\n",
      "  Train results batch 54, loss 0.270109\n",
      "  Train results batch 55, loss 0.209781\n",
      "  Train results batch 56, loss 0.184856\n",
      "  Train results batch 57, loss 0.144697\n",
      "  Train results batch 58, loss 0.157423\n",
      "  Train results batch 59, loss 0.148453\n",
      "  Train results batch 60, loss 0.15593\n",
      "  Train results batch 61, loss 0.208208\n",
      "  Train results batch 62, loss 0.128562\n",
      "  Train results batch 63, loss 0.125574\n",
      "  Train results batch 64, loss 0.117829\n",
      "  Train results batch 65, loss 0.156416\n",
      "  Train results batch 66, loss 0.145022\n",
      "  Train results batch 67, loss 0.11528\n",
      "  Train results batch 68, loss 0.0901122\n",
      "  Train results batch 69, loss 0.101886\n",
      "  Train results batch 70, loss 0.120888\n",
      "  Train results batch 71, loss 0.109394\n",
      "  Train results batch 72, loss 0.0944825\n",
      "  Train results batch 73, loss 0.0990459\n",
      "  Train results batch 74, loss 0.0890952\n",
      "  Train results batch 75, loss 0.085438\n",
      "  Train results batch 76, loss 0.0908556\n",
      "  Train results batch 77, loss 0.0789046\n",
      "  Train results batch 78, loss 0.0909173\n",
      "  Train results batch 79, loss 0.0838394\n",
      "  Train results batch 80, loss 0.0849668\n",
      "  Train results batch 81, loss 0.0606947\n",
      "  Train results batch 82, loss 0.0728937\n",
      "  Train results batch 83, loss 0.0617816\n",
      "  Train results batch 84, loss 0.0662275\n",
      "  Train results batch 85, loss 0.0620523\n",
      "  Train results batch 86, loss 0.0672548\n",
      "  Train results batch 87, loss 0.0654088\n",
      "  Train results batch 88, loss 0.089841\n",
      "  Train results batch 89, loss 0.0781615\n",
      "  Train results batch 90, loss 0.0621954\n",
      "  Train results batch 91, loss 0.0684847\n",
      "  Train results batch 92, loss 0.0782627\n",
      "  Train results batch 93, loss 0.0658948\n",
      "  Train results batch 94, loss 0.0633943\n",
      "  Train results batch 95, loss 0.0818804\n",
      "  Train results batch 96, loss 0.0721816\n",
      "  Train results batch 97, loss 0.070587\n",
      "  Train results batch 98, loss 0.059385\n",
      "  Train results batch 99, loss 0.0748218\n",
      "  Train results batch 100, loss 0.072974\n",
      "  Train results batch 101, loss 0.0521744\n",
      "  Train results batch 102, loss 0.0762887\n",
      "  Train results batch 103, loss 0.0761788\n",
      "  Train results batch 104, loss 0.0706823\n",
      "  Train results batch 105, loss 0.0687109\n",
      "  Train results batch 106, loss 0.0539401\n",
      "  Train results batch 107, loss 0.0614513\n",
      "  Train results batch 108, loss 0.070258\n",
      "  Train results batch 109, loss 0.0644847\n",
      "  Train results batch 110, loss 0.0611265\n",
      "  Train results batch 111, loss 0.0533926\n",
      "  Train results batch 112, loss 0.0638834\n",
      "  Train results batch 113, loss 0.0559928\n",
      "  Train results batch 114, loss 0.0581019\n",
      "  Train results batch 115, loss 0.0746805\n",
      "  Train results batch 116, loss 0.0603277\n",
      "  Train results batch 117, loss 0.0695728\n",
      "  Train results batch 118, loss 0.0638924\n",
      "  Train results batch 119, loss 0.0624111\n",
      "  Train results batch 120, loss 0.0542529\n",
      "  Train results batch 121, loss 0.0669073\n",
      "  Train results batch 122, loss 0.0640695\n",
      "  Train results batch 123, loss 0.0620505\n",
      "  Train results batch 124, loss 0.0600626\n",
      "  Train results batch 125, loss 0.073503\n",
      "  Train results batch 126, loss 0.0699377\n",
      "  Train results batch 127, loss 0.0750774\n",
      "  Train results batch 128, loss 0.0743382\n",
      "  Train results batch 129, loss 0.0797975\n",
      "  Train results batch 130, loss 0.0634367\n",
      "  Train results batch 131, loss 0.0643889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train results batch 132, loss 0.0565818\n",
      "  Train results batch 133, loss 0.0580997\n",
      "  Train results batch 134, loss 0.0700472\n",
      "  Train results batch 135, loss 0.0697948\n",
      "  Train results batch 136, loss 0.0695701\n",
      "  Train results batch 137, loss 0.0610017\n",
      "  Train results batch 138, loss 0.0691938\n",
      "  Train results batch 139, loss 0.0648346\n",
      "  Train results batch 140, loss 0.0615873\n",
      "  Train results batch 141, loss 0.0634703\n",
      "  Train results batch 142, loss 0.0643701\n",
      "  Train results batch 143, loss 0.0609675\n",
      "  Train results batch 144, loss 0.068244\n",
      "  Train results batch 145, loss 0.0717636\n",
      "  Train results batch 146, loss 0.0482297\n",
      "  Train results batch 147, loss 0.0550336\n",
      "  Train results batch 148, loss 0.0626072\n",
      "  Train results batch 149, loss 0.0519962\n",
      "  Train results batch 150, loss 0.0757212\n",
      "  Train results batch 151, loss 0.0599381\n",
      "  Train results batch 152, loss 0.0645147\n",
      "  Train results batch 153, loss 0.0609304\n",
      "  Train results batch 154, loss 0.061447\n",
      "  Train results batch 155, loss 0.0571928\n",
      "  Train results batch 156, loss 0.0633725\n",
      "  Train results batch 157, loss 0.0569411\n",
      "  Train results batch 158, loss 0.0544232\n",
      "  Train results batch 159, loss 0.0554718\n",
      "  Train results batch 160, loss 0.0628469\n",
      "  Train results batch 161, loss 0.0479276\n",
      "  Train results batch 162, loss 0.0527546\n",
      "  Train results batch 163, loss 0.0605292\n",
      "  Train results batch 164, loss 0.0721873\n",
      "  Train results batch 165, loss 0.0524282\n",
      "  Train results batch 166, loss 0.0644465\n",
      "  Train results batch 167, loss 0.0533383\n",
      "  Train results batch 168, loss 0.0510248\n",
      "  Train results batch 169, loss 0.0557256\n",
      "  Train results batch 170, loss 0.0612035\n",
      "  Train results batch 171, loss 0.060852\n",
      "  Train results batch 172, loss 0.0691233\n",
      "  Train results batch 173, loss 0.0619603\n",
      "  Train results batch 174, loss 0.0854477\n",
      "  Train results batch 175, loss 0.0637755\n",
      "  Train results batch 176, loss 0.0664569\n",
      "  Train results batch 177, loss 0.0651873\n",
      "  Train results batch 178, loss 0.0508555\n",
      "  Train results batch 179, loss 0.0752666\n",
      "  Train results batch 180, loss 0.0578317\n",
      "  Train results batch 181, loss 0.0678729\n",
      "  Train results batch 182, loss 0.0576916\n",
      "  Train results batch 183, loss 0.053349\n",
      "  Train results batch 184, loss 0.0549862\n",
      "  Train results batch 185, loss 0.0696869\n",
      "  Train results batch 186, loss 0.0608531\n",
      "  Train results batch 187, loss 0.0648836\n",
      "  Train results batch 188, loss 0.0553399\n",
      "  Train results batch 189, loss 0.054052\n",
      "  Train results batch 190, loss 0.0677113\n",
      "  Train results batch 191, loss 0.0623945\n",
      "  Train results batch 192, loss 0.0563941\n",
      "  Train results batch 193, loss 0.0737067\n",
      "  Train results batch 194, loss 0.0592233\n",
      "  Train results batch 195, loss 0.0499377\n",
      "  Train results batch 196, loss 0.0658908\n",
      "  Train results batch 197, loss 0.0670756\n",
      "  Train results batch 198, loss 0.0553283\n",
      "  Train results batch 199, loss 0.0594734\n",
      "  Train results batch 200, loss 0.0711894\n",
      "  Train results batch 201, loss 0.0501994\n",
      "  Train results batch 202, loss 0.0712994\n",
      "  Train results batch 203, loss 0.0611685\n",
      "  Train results batch 204, loss 0.0636282\n",
      "  Train results batch 205, loss 0.0661724\n",
      "  Train results batch 206, loss 0.0606286\n",
      "  Train results batch 207, loss 0.0629345\n",
      "  Train results batch 208, loss 0.0497847\n",
      "  Train results batch 209, loss 0.0705399\n",
      "  Train results batch 210, loss 0.053483\n",
      "  Train results batch 211, loss 0.069663\n",
      "  Train results batch 212, loss 0.064465\n",
      "  Train results batch 213, loss 0.048241\n",
      "  Train results batch 214, loss 0.0571026\n",
      "  Train results batch 215, loss 0.0613656\n",
      "  Train results batch 216, loss 0.06006\n",
      "  Train results batch 217, loss 0.0466405\n",
      "  Train results batch 218, loss 0.0513305\n",
      "  Train results batch 219, loss 0.0684746\n",
      "  Train results batch 220, loss 0.0631749\n",
      "  Train results batch 221, loss 0.0536252\n",
      "  Train results batch 222, loss 0.0579743\n",
      "  Train results batch 223, loss 0.0579941\n",
      "  Train results batch 224, loss 0.065729\n",
      "  Train results batch 225, loss 0.0614101\n",
      "  Train results batch 226, loss 0.0645488\n",
      "  Train results batch 227, loss 0.0542732\n",
      "  Train results batch 228, loss 0.0661041\n",
      "  Train results batch 229, loss 0.0587642\n",
      "  Train results batch 230, loss 0.0636962\n",
      "  Train results batch 231, loss 0.0685932\n",
      "  Train results batch 232, loss 0.0427758\n",
      "  Train results batch 233, loss 0.0511586\n",
      "Training results epoch 0, loss 0.0232001390063\n",
      "  Dev results batch 0, loss 0.0677608\n",
      "  Dev results batch 1, loss 0.057319\n",
      "  Dev results batch 2, loss 0.0769927\n",
      "  Dev results batch 3, loss 0.0483853\n",
      "  Dev results batch 4, loss 0.0618623\n",
      "  Dev results batch 5, loss 0.0658939\n",
      "  Dev results batch 6, loss 0.0624023\n",
      "  Dev results batch 7, loss 0.0557431\n",
      "  Dev results batch 8, loss 0.0586888\n",
      "  Dev results batch 9, loss 0.0617443\n",
      "  Dev results batch 10, loss 0.0590259\n",
      "  Dev results batch 11, loss 0.0688222\n",
      "  Dev results batch 12, loss 0.064715\n",
      "  Dev results batch 13, loss 0.0568016\n",
      "  Dev results batch 14, loss 0.0582242\n",
      "  Dev results batch 15, loss 0.0677952\n",
      "  Dev results batch 16, loss 0.0533797\n",
      "  Dev results batch 17, loss 0.0582341\n",
      "  Dev results batch 18, loss 0.0456749\n",
      "  Dev results batch 19, loss 0.0546015\n",
      "  Dev results batch 20, loss 0.0620518\n",
      "  Dev results batch 21, loss 0.0576725\n",
      "  Dev results batch 22, loss 0.0504716\n",
      "  Dev results batch 23, loss 0.0603724\n",
      "  Dev results batch 24, loss 0.0522012\n",
      "  Dev results batch 25, loss 0.0615665\n",
      "  Dev results batch 26, loss 0.0635514\n",
      "  Dev results batch 27, loss 0.069626\n",
      "  Dev results batch 28, loss 0.0652161\n",
      "  Dev results batch 29, loss 0.0601779\n",
      "  Dev results batch 30, loss 0.0567786\n",
      "  Dev results batch 31, loss 0.0551725\n",
      "  Dev results batch 32, loss 0.0549062\n",
      "  Dev results batch 33, loss 0.0571346\n",
      "  Dev results batch 34, loss 0.0638037\n",
      "  Dev results batch 35, loss 0.0792435\n",
      "  Dev results batch 36, loss 0.0623024\n",
      "  Dev results batch 37, loss 0.0574351\n",
      "  Dev results batch 38, loss 0.0612829\n",
      "  Dev results batch 39, loss 0.0611535\n",
      "  Dev results batch 40, loss 0.0638988\n",
      "  Dev results batch 41, loss 0.0459953\n",
      "  Dev results batch 42, loss 0.0851032\n",
      "  Dev results batch 43, loss 0.0510295\n",
      "  Dev results batch 44, loss 0.0596452\n",
      "  Dev results batch 45, loss 0.0663665\n",
      "  Dev results batch 46, loss 0.0755444\n",
      "  Dev results batch 47, loss 0.058838\n",
      "  Dev results batch 48, loss 0.0634665\n",
      "  Dev results batch 49, loss 0.059907\n",
      "  Dev results batch 50, loss 0.0569378\n",
      "  Dev results batch 51, loss 0.0662642\n",
      "  Dev results batch 52, loss 0.0567576\n",
      "  Dev results batch 53, loss 0.0541223\n",
      "  Dev results batch 54, loss 0.0600409\n",
      "  Dev results batch 55, loss 0.0520981\n",
      "  Dev results batch 56, loss 0.0659995\n",
      "  Dev results batch 57, loss 0.0652796\n",
      "  Dev results batch 58, loss 0.0638106\n",
      "  Dev results batch 59, loss 0.0770332\n",
      "  Dev results batch 60, loss 0.0485618\n",
      "  Dev results batch 61, loss 0.0591796\n",
      "  Dev results batch 62, loss 0.0659099\n",
      "  Dev results batch 63, loss 0.0675609\n",
      "  Dev results batch 64, loss 0.0530696\n",
      "  Dev results batch 65, loss 0.0490252\n",
      "  Dev results batch 66, loss 0.0534339\n",
      "  Dev results batch 67, loss 0.0609247\n",
      "  Dev results batch 68, loss 0.0726524\n",
      "  Dev results batch 69, loss 0.0676093\n",
      "  Dev results batch 70, loss 0.0685919\n",
      "  Dev results batch 71, loss 0.0584346\n",
      "  Dev results batch 72, loss 0.0583399\n",
      "  Dev results batch 73, loss 0.0682757\n",
      "  Dev results batch 74, loss 0.0680898\n",
      "  Dev results batch 75, loss 0.061508\n",
      "  Dev results batch 76, loss 0.0645767\n",
      "  Dev results batch 77, loss 0.0543946\n",
      "Dev results epoch 0, loss 0.000476971071369\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "ConcatOp : Dimensions of inputs should match: shape[0] = [1,1] vs. shape[1] = [128,16]\n\t [[Node: rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/lstm_cell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](rnn/while/TensorArrayReadV3, rnn/while/Switch_3:1, rnn/while/rnn/multi_rnn_cell/cell_2/cell_2/lstm_cell/split/split_dim)]]\n\nCaused by op 'rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/lstm_cell/concat', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-b8b3461b5ccb>\", line 4, in <module>\n    outputs, state = tf.nn.dynamic_rnn(hidden_network, inputs, dtype=tf.float32, initial_state=rnn_tuple_state, )\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 614, in dynamic_rnn\n    dtype=dtype)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 777, in _dynamic_rnn_loop\n    swap_memory=swap_memory)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2816, in while_loop\n    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2640, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2590, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 762, in _time_step\n    (output, new_state) = call_cell()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 748, in <lambda>\n    call_cell = lambda: cell(input_t, state)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 183, in __call__\n    return super(RNNCell, self).__call__(inputs, state)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 575, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 1066, in call\n    cur_inp, new_state = cell(cur_inp, cur_state)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 183, in __call__\n    return super(RNNCell, self).__call__(inputs, state)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 575, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 611, in call\n    lstm_matrix = self._linear1([inputs, m_prev])\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 1189, in __call__\n    res = math_ops.matmul(array_ops.concat(args, 1), self._weights)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 1099, in concat\n    return gen_array_ops._concat_v2(values=values, axis=axis, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 706, in _concat_v2\n    \"ConcatV2\", values=values, axis=axis, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): ConcatOp : Dimensions of inputs should match: shape[0] = [1,1] vs. shape[1] = [128,16]\n\t [[Node: rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/lstm_cell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](rnn/while/TensorArrayReadV3, rnn/while/Switch_3:1, rnn/while/rnn/multi_rnn_cell/cell_2/cell_2/lstm_cell/split/split_dim)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: ConcatOp : Dimensions of inputs should match: shape[0] = [1,1] vs. shape[1] = [128,16]\n\t [[Node: rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/lstm_cell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](rnn/while/TensorArrayReadV3, rnn/while/Switch_3:1, rnn/while/rnn/multi_rnn_cell/cell_2/cell_2/lstm_cell/split/split_dim)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c4dd4a31d47b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mloss_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_dev_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mti\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mgenerate_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0mgenerate_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-c4dd4a31d47b>\u001b[0m in \u001b[0;36mgenerate_graph\u001b[0;34m(graph_size)\u001b[0m\n\u001b[1;32m     38\u001b[0m             _state_packed , _prediction = sess.run(\n\u001b[1;32m     39\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mstate_packed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 feed_dict={learning_rate: 0.02, inputs: tmp_batch})\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             _state_packed , _prediction = sess.run(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: ConcatOp : Dimensions of inputs should match: shape[0] = [1,1] vs. shape[1] = [128,16]\n\t [[Node: rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/lstm_cell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](rnn/while/TensorArrayReadV3, rnn/while/Switch_3:1, rnn/while/rnn/multi_rnn_cell/cell_2/cell_2/lstm_cell/split/split_dim)]]\n\nCaused by op 'rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/lstm_cell/concat', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-b8b3461b5ccb>\", line 4, in <module>\n    outputs, state = tf.nn.dynamic_rnn(hidden_network, inputs, dtype=tf.float32, initial_state=rnn_tuple_state, )\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 614, in dynamic_rnn\n    dtype=dtype)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 777, in _dynamic_rnn_loop\n    swap_memory=swap_memory)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2816, in while_loop\n    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2640, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2590, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 762, in _time_step\n    (output, new_state) = call_cell()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 748, in <lambda>\n    call_cell = lambda: cell(input_t, state)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 183, in __call__\n    return super(RNNCell, self).__call__(inputs, state)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 575, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 1066, in call\n    cur_inp, new_state = cell(cur_inp, cur_state)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 183, in __call__\n    return super(RNNCell, self).__call__(inputs, state)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 575, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 611, in call\n    lstm_matrix = self._linear1([inputs, m_prev])\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 1189, in __call__\n    res = math_ops.matmul(array_ops.concat(args, 1), self._weights)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 1099, in concat\n    return gen_array_ops._concat_v2(values=values, axis=axis, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 706, in _concat_v2\n    \"ConcatV2\", values=values, axis=axis, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): ConcatOp : Dimensions of inputs should match: shape[0] = [1,1] vs. shape[1] = [128,16]\n\t [[Node: rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/lstm_cell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](rnn/while/TensorArrayReadV3, rnn/while/Switch_3:1, rnn/while/rnn/multi_rnn_cell/cell_2/cell_2/lstm_cell/split/split_dim)]]\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle (start_indices)\n",
    "train_indices = start_indices[0:int(train_size)]\n",
    "dev_indices= start_indices[int(train_size):int(train_size+dev_size)]\n",
    "test_indices = start_indices[int(train_size+dev_size):int(train_size+dev_size+test_size)]\n",
    "\n",
    "epoch_count = 5\n",
    "\n",
    "loss_results = np.zeros((epoch_count,2))\n",
    "\n",
    "def get_dev_loss():\n",
    "    epoch_dev_loss = 0.0\n",
    "    for devi in range(dev_batch_count):\n",
    "        batch_inputs,batch_targets = get_batch(devi, dev_indices)\n",
    "\n",
    "        batch_dev_loss = sess.run(loss,feed_dict={inputs:batch_inputs,targets:batch_targets})\n",
    "        print(\"  Dev results batch %d, loss %s\" %(  devi, str(batch_dev_loss)))  \n",
    "\n",
    "        epoch_dev_loss += batch_dev_loss\n",
    "        #sys.stdout.write('.')\n",
    "        #sys.stdout.flush()\n",
    "    return epoch_dev_loss / dev_size\n",
    "\n",
    "def generate_graph(graph_size=200):\n",
    "    prime_size = 20\n",
    "    \n",
    "    prime_signal_start_i = 0\n",
    "    \n",
    "    tmp_signal = np.zeros((graph_size,1))\n",
    "    tmp_signal[0:prime_size,0] = signal_amp[prime_signal_start_i:(prime_signal_start_i+prime_size)]\n",
    "    #tmp_signal[0:prime_size,0] = np.random.normal(size=prime_size)*0.6+0.1\n",
    "    tmp_batch = np.zeros((1,sequence_length,1))\n",
    "    \n",
    "    _state_packed = None\n",
    "    for end in range(prime_size, graph_size):\n",
    "        #end = prime_size\n",
    "        tmp_batch[0,:,0] = tmp_signal.take(range((end-sequence_length),end), mode='wrap')\n",
    "        if _state_packed is None:\n",
    "            _state_packed , _prediction = sess.run(\n",
    "                [state_packed, predictions[0,0]], \n",
    "                feed_dict={learning_rate: 0.02, inputs: tmp_batch})\n",
    "        else:\n",
    "            _state_packed , _prediction = sess.run(\n",
    "                [state_packed, predictions[0,0]], \n",
    "                feed_dict={learning_rate: 0.02, initial_state: _state_packed, inputs: tmp_batch})\n",
    "            \n",
    "        #print(_prediction)\n",
    "        tmp_signal[end,0] = _prediction\n",
    "        sys.stdout.write('.')\n",
    "        sys.stdout.flush()\n",
    "    print(\"\")\n",
    "    plotly.offline.iplot({\n",
    "       \"data\": [Scatter(y=tmp_signal[:,0])],\n",
    "       \"layout\": Layout(title=\"\")})\n",
    "\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    epoch_dev_loss = get_dev_loss()    \n",
    "\n",
    "    #print(\"\")            \n",
    "    print(\"Dev results epoch start, loss %s\" %(  str(epoch_dev_loss),))  \n",
    "\n",
    "    for epoch in range(0,epoch_count):\n",
    "        np.random.shuffle (train_indices)\n",
    "        epoch_train_loss = 0.0\n",
    "        for ti in range(train_batch_count):\n",
    "            batch_inputs,batch_targets = get_batch(ti, train_indices)\n",
    "\n",
    "            batch_train_loss, _ = sess.run([loss, opt], feed_dict={learning_rate: 0.002, inputs: batch_inputs, targets: batch_targets})\n",
    "            print(\"  Train results batch %d, loss %s\" %(  ti, str(batch_train_loss)))  \n",
    "            epoch_train_loss += batch_train_loss\n",
    "            #sys.stdout.write('.')\n",
    "            #sys.stdout.flush()\n",
    "        #print(\"\")\n",
    "        epoch_train_loss = epoch_train_loss / train_size\n",
    "        print(\"Training results epoch %d, loss %s\" %( epoch, str(epoch_train_loss)))\n",
    "        epoch_dev_loss = get_dev_loss()    \n",
    "        #print(\"\")            \n",
    "        print(\"Dev results epoch %d, loss %s\" %( epoch, str(epoch_dev_loss)))  \n",
    "        loss_results[epoch,0] = epoch_train_loss\n",
    "        loss_results[epoch,1] = epoch_dev_loss\n",
    "        ti += 1\n",
    "        generate_graph()\n",
    "    generate_graph(graph_size=1000)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
