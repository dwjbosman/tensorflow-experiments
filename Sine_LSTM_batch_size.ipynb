{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly\n",
    "from plotly.graph_objs import Scatter, Layout\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "import IPython.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_length = 50001\n",
    "time_per_sample = 0.01\n",
    "signal_time = np.linspace(num=sample_length,start = 0, stop = sample_length * time_per_sample )\n",
    "signal_amp = np.sin(signal_time*2*np.pi) + np.random.normal(size=sample_length)*0.02\n",
    "    #np.sin(2+signal_time*1.7*np.pi)*0.5 + \\\n",
    "    #np.sin(1+signal_time*2.2*np.pi) + \\\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "type": "scatter",
         "x": [
          0,
          0.010000199999999999,
          0.020000399999999998,
          0.030000599999999995,
          0.040000799999999996,
          0.050001,
          0.06000119999999999,
          0.07000139999999999,
          0.08000159999999999,
          0.09000179999999999,
          0.100002,
          0.1100022,
          0.12000239999999998,
          0.1300026,
          0.14000279999999998,
          0.150003,
          0.16000319999999998,
          0.17000339999999997,
          0.18000359999999999,
          0.19000379999999997,
          0.200004,
          0.21000419999999997,
          0.2200044,
          0.23000459999999998,
          0.24000479999999996,
          0.250005,
          0.2600052,
          0.27000539999999995,
          0.28000559999999997,
          0.2900058,
          0.300006,
          0.31000619999999995,
          0.32000639999999997,
          0.3300066,
          0.34000679999999994,
          0.35000699999999996,
          0.36000719999999997,
          0.3700074,
          0.38000759999999995,
          0.39000779999999996,
          0.400008,
          0.41000819999999993,
          0.42000839999999995,
          0.43000859999999996,
          0.4400088,
          0.45000899999999994,
          0.46000919999999995,
          0.47000939999999997,
          0.4800095999999999,
          0.49000979999999994,
          0.50001,
          0.5100102,
          0.5200104,
          0.5300106,
          0.5400107999999999,
          0.5500109999999999,
          0.5600111999999999,
          0.5700114,
          0.5800116,
          0.5900118,
          0.600012,
          0.6100121999999999,
          0.6200123999999999,
          0.6300125999999999,
          0.6400127999999999,
          0.650013,
          0.6600132,
          0.6700134,
          0.6800135999999999,
          0.6900137999999999,
          0.7000139999999999,
          0.7100141999999999,
          0.7200143999999999,
          0.7300146,
          0.7400148,
          0.7500149999999999,
          0.7600151999999999,
          0.7700153999999999,
          0.7800155999999999,
          0.7900157999999999,
          0.800016,
          0.8100162,
          0.8200163999999999,
          0.8300165999999999,
          0.8400167999999999,
          0.8500169999999999,
          0.8600171999999999,
          0.8700173999999999,
          0.8800176,
          0.8900177999999999,
          0.9000179999999999,
          0.9100181999999999,
          0.9200183999999999,
          0.9300185999999999,
          0.9400187999999999,
          0.950019,
          0.9600191999999999,
          0.9700193999999999,
          0.9800195999999999,
          0.9900197999999999
         ],
         "y": [
          0.02100441779024228,
          0.05277031418951649,
          0.14266606432835252,
          0.1745700104383511,
          0.20310682769512606,
          0.33669262432805963,
          0.3525368448440776,
          0.4190592531157332,
          0.463315199074097,
          0.5375976963819442,
          0.58789528625443,
          0.6152813672335701,
          0.672634316100781,
          0.7145280785701134,
          0.7754661128606813,
          0.7913020521887482,
          0.8213701272545233,
          0.8614667741103499,
          0.8995519572528329,
          0.9223724762030191,
          0.9743376181172227,
          0.953828072918774,
          0.9788121914415852,
          1.0006443813599075,
          1.0140008905880105,
          1.0232138583422317,
          1.0061962705918306,
          0.9830959702183979,
          0.9747648859596305,
          0.9649626878048645,
          0.9536336704035668,
          0.9123457582233392,
          0.9137875120795315,
          0.8433712765639683,
          0.869011256181243,
          0.7675475972376811,
          0.7648084235521826,
          0.7684205176029308,
          0.6884757477050287,
          0.6642104855691919,
          0.605454258154298,
          0.5257772855761145,
          0.4861340289548857,
          0.4381331238978326,
          0.3774056236386079,
          0.3312866434736604,
          0.25620594175696576,
          0.1862487723027827,
          0.10003885498281231,
          0.050634802998328815,
          -0.037128018348940084,
          -0.060360097507404564,
          -0.09067816111207129,
          -0.17039874919596273,
          -0.23262725411106538,
          -0.31181229449306525,
          -0.3843627305863391,
          -0.4331484955823563,
          -0.47079263164680707,
          -0.5333684752064662,
          -0.6044902247025635,
          -0.6268196674541748,
          -0.6541260220793622,
          -0.7058670886474178,
          -0.7762035757849644,
          -0.8361550675496412,
          -0.8754044212104181,
          -0.8718219269540214,
          -0.903124559705186,
          -0.9270119831831927,
          -0.947835131843494,
          -0.9325503411841246,
          -0.9929579009539787,
          -1.0087260998813177,
          -0.9705532811686436,
          -1.000161604722138,
          -0.9760326342996241,
          -1.002407645457539,
          -0.9883659142312322,
          -0.9611432015313723,
          -0.9950035542914218,
          -0.9357445069310186,
          -0.8771485507974196,
          -0.8782079542432136,
          -0.8382139364754994,
          -0.8650064774777149,
          -0.77884281679025,
          -0.7122986853778788,
          -0.6930678851925878,
          -0.5982897461975563,
          -0.5719707815431059,
          -0.5344270193748067,
          -0.48323387782413674,
          -0.4481283218476211,
          -0.3541446031058582,
          -0.30789460903959587,
          -0.2575038983890612,
          -0.19620749619401898,
          -0.14025237417191772,
          -0.05005347838449118
         ]
        }
       ],
       "layout": {
        "title": ""
       }
      },
      "text/html": [
       "<div id=\"7001b38a-7279-413d-8d22-ffff03a9408f\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"7001b38a-7279-413d-8d22-ffff03a9408f\", [{\"x\": [0.0, 0.010000199999999999, 0.020000399999999998, 0.030000599999999995, 0.040000799999999996, 0.050001, 0.06000119999999999, 0.07000139999999999, 0.08000159999999999, 0.09000179999999999, 0.100002, 0.1100022, 0.12000239999999998, 0.1300026, 0.14000279999999998, 0.150003, 0.16000319999999998, 0.17000339999999997, 0.18000359999999999, 0.19000379999999997, 0.200004, 0.21000419999999997, 0.2200044, 0.23000459999999998, 0.24000479999999996, 0.250005, 0.2600052, 0.27000539999999995, 0.28000559999999997, 0.2900058, 0.300006, 0.31000619999999995, 0.32000639999999997, 0.3300066, 0.34000679999999994, 0.35000699999999996, 0.36000719999999997, 0.3700074, 0.38000759999999995, 0.39000779999999996, 0.400008, 0.41000819999999993, 0.42000839999999995, 0.43000859999999996, 0.4400088, 0.45000899999999994, 0.46000919999999995, 0.47000939999999997, 0.4800095999999999, 0.49000979999999994, 0.50001, 0.5100102, 0.5200104, 0.5300106, 0.5400107999999999, 0.5500109999999999, 0.5600111999999999, 0.5700114, 0.5800116, 0.5900118, 0.600012, 0.6100121999999999, 0.6200123999999999, 0.6300125999999999, 0.6400127999999999, 0.650013, 0.6600132, 0.6700134, 0.6800135999999999, 0.6900137999999999, 0.7000139999999999, 0.7100141999999999, 0.7200143999999999, 0.7300146, 0.7400148, 0.7500149999999999, 0.7600151999999999, 0.7700153999999999, 0.7800155999999999, 0.7900157999999999, 0.800016, 0.8100162, 0.8200163999999999, 0.8300165999999999, 0.8400167999999999, 0.8500169999999999, 0.8600171999999999, 0.8700173999999999, 0.8800176, 0.8900177999999999, 0.9000179999999999, 0.9100181999999999, 0.9200183999999999, 0.9300185999999999, 0.9400187999999999, 0.950019, 0.9600191999999999, 0.9700193999999999, 0.9800195999999999, 0.9900197999999999], \"y\": [0.02100441779024228, 0.05277031418951649, 0.14266606432835252, 0.1745700104383511, 0.20310682769512606, 0.33669262432805963, 0.3525368448440776, 0.4190592531157332, 0.463315199074097, 0.5375976963819442, 0.58789528625443, 0.6152813672335701, 0.672634316100781, 0.7145280785701134, 0.7754661128606813, 0.7913020521887482, 0.8213701272545233, 0.8614667741103499, 0.8995519572528329, 0.9223724762030191, 0.9743376181172227, 0.953828072918774, 0.9788121914415852, 1.0006443813599075, 1.0140008905880105, 1.0232138583422317, 1.0061962705918306, 0.9830959702183979, 0.9747648859596305, 0.9649626878048645, 0.9536336704035668, 0.9123457582233392, 0.9137875120795315, 0.8433712765639683, 0.869011256181243, 0.7675475972376811, 0.7648084235521826, 0.7684205176029308, 0.6884757477050287, 0.6642104855691919, 0.605454258154298, 0.5257772855761145, 0.4861340289548857, 0.4381331238978326, 0.3774056236386079, 0.3312866434736604, 0.25620594175696576, 0.1862487723027827, 0.10003885498281231, 0.050634802998328815, -0.037128018348940084, -0.060360097507404564, -0.09067816111207129, -0.17039874919596273, -0.23262725411106538, -0.31181229449306525, -0.3843627305863391, -0.4331484955823563, -0.47079263164680707, -0.5333684752064662, -0.6044902247025635, -0.6268196674541748, -0.6541260220793622, -0.7058670886474178, -0.7762035757849644, -0.8361550675496412, -0.8754044212104181, -0.8718219269540214, -0.903124559705186, -0.9270119831831927, -0.947835131843494, -0.9325503411841246, -0.9929579009539787, -1.0087260998813177, -0.9705532811686436, -1.000161604722138, -0.9760326342996241, -1.002407645457539, -0.9883659142312322, -0.9611432015313723, -0.9950035542914218, -0.9357445069310186, -0.8771485507974196, -0.8782079542432136, -0.8382139364754994, -0.8650064774777149, -0.77884281679025, -0.7122986853778788, -0.6930678851925878, -0.5982897461975563, -0.5719707815431059, -0.5344270193748067, -0.48323387782413674, -0.4481283218476211, -0.3541446031058582, -0.30789460903959587, -0.2575038983890612, -0.19620749619401898, -0.14025237417191772, -0.05005347838449118], \"type\": \"scatter\"}], {\"title\": \"\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"7001b38a-7279-413d-8d22-ffff03a9408f\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"7001b38a-7279-413d-8d22-ffff03a9408f\", [{\"x\": [0.0, 0.010000199999999999, 0.020000399999999998, 0.030000599999999995, 0.040000799999999996, 0.050001, 0.06000119999999999, 0.07000139999999999, 0.08000159999999999, 0.09000179999999999, 0.100002, 0.1100022, 0.12000239999999998, 0.1300026, 0.14000279999999998, 0.150003, 0.16000319999999998, 0.17000339999999997, 0.18000359999999999, 0.19000379999999997, 0.200004, 0.21000419999999997, 0.2200044, 0.23000459999999998, 0.24000479999999996, 0.250005, 0.2600052, 0.27000539999999995, 0.28000559999999997, 0.2900058, 0.300006, 0.31000619999999995, 0.32000639999999997, 0.3300066, 0.34000679999999994, 0.35000699999999996, 0.36000719999999997, 0.3700074, 0.38000759999999995, 0.39000779999999996, 0.400008, 0.41000819999999993, 0.42000839999999995, 0.43000859999999996, 0.4400088, 0.45000899999999994, 0.46000919999999995, 0.47000939999999997, 0.4800095999999999, 0.49000979999999994, 0.50001, 0.5100102, 0.5200104, 0.5300106, 0.5400107999999999, 0.5500109999999999, 0.5600111999999999, 0.5700114, 0.5800116, 0.5900118, 0.600012, 0.6100121999999999, 0.6200123999999999, 0.6300125999999999, 0.6400127999999999, 0.650013, 0.6600132, 0.6700134, 0.6800135999999999, 0.6900137999999999, 0.7000139999999999, 0.7100141999999999, 0.7200143999999999, 0.7300146, 0.7400148, 0.7500149999999999, 0.7600151999999999, 0.7700153999999999, 0.7800155999999999, 0.7900157999999999, 0.800016, 0.8100162, 0.8200163999999999, 0.8300165999999999, 0.8400167999999999, 0.8500169999999999, 0.8600171999999999, 0.8700173999999999, 0.8800176, 0.8900177999999999, 0.9000179999999999, 0.9100181999999999, 0.9200183999999999, 0.9300185999999999, 0.9400187999999999, 0.950019, 0.9600191999999999, 0.9700193999999999, 0.9800195999999999, 0.9900197999999999], \"y\": [0.02100441779024228, 0.05277031418951649, 0.14266606432835252, 0.1745700104383511, 0.20310682769512606, 0.33669262432805963, 0.3525368448440776, 0.4190592531157332, 0.463315199074097, 0.5375976963819442, 0.58789528625443, 0.6152813672335701, 0.672634316100781, 0.7145280785701134, 0.7754661128606813, 0.7913020521887482, 0.8213701272545233, 0.8614667741103499, 0.8995519572528329, 0.9223724762030191, 0.9743376181172227, 0.953828072918774, 0.9788121914415852, 1.0006443813599075, 1.0140008905880105, 1.0232138583422317, 1.0061962705918306, 0.9830959702183979, 0.9747648859596305, 0.9649626878048645, 0.9536336704035668, 0.9123457582233392, 0.9137875120795315, 0.8433712765639683, 0.869011256181243, 0.7675475972376811, 0.7648084235521826, 0.7684205176029308, 0.6884757477050287, 0.6642104855691919, 0.605454258154298, 0.5257772855761145, 0.4861340289548857, 0.4381331238978326, 0.3774056236386079, 0.3312866434736604, 0.25620594175696576, 0.1862487723027827, 0.10003885498281231, 0.050634802998328815, -0.037128018348940084, -0.060360097507404564, -0.09067816111207129, -0.17039874919596273, -0.23262725411106538, -0.31181229449306525, -0.3843627305863391, -0.4331484955823563, -0.47079263164680707, -0.5333684752064662, -0.6044902247025635, -0.6268196674541748, -0.6541260220793622, -0.7058670886474178, -0.7762035757849644, -0.8361550675496412, -0.8754044212104181, -0.8718219269540214, -0.903124559705186, -0.9270119831831927, -0.947835131843494, -0.9325503411841246, -0.9929579009539787, -1.0087260998813177, -0.9705532811686436, -1.000161604722138, -0.9760326342996241, -1.002407645457539, -0.9883659142312322, -0.9611432015313723, -0.9950035542914218, -0.9357445069310186, -0.8771485507974196, -0.8782079542432136, -0.8382139364754994, -0.8650064774777149, -0.77884281679025, -0.7122986853778788, -0.6930678851925878, -0.5982897461975563, -0.5719707815431059, -0.5344270193748067, -0.48323387782413674, -0.4481283218476211, -0.3541446031058582, -0.30789460903959587, -0.2575038983890612, -0.19620749619401898, -0.14025237417191772, -0.05005347838449118], \"type\": \"scatter\"}], {\"title\": \"\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s_i = 0\n",
    "e_i = s_i + 100\n",
    "x = plotly.offline.iplot({\n",
    "    \"data\": [Scatter(x=signal_time[s_i:e_i],y=signal_amp[s_i:e_i])],\n",
    "    \"layout\": Layout(title=\"\")\n",
    "    \n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 50\n",
    "prediction_length = 1\n",
    "input_feature_count = 1\n",
    "output_feature_count = 1\n",
    "batch_size = 128 #512\n",
    "hidden_count_per_layer = [16,16,16]\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, [None, sequence_length, input_feature_count], name = 'inputs')\n",
    "targets = tf.placeholder(tf.float32, [None, output_feature_count], name = 'targets')\n",
    "keep_prob = tf.placeholder(tf.float32, name = 'keep')\n",
    "learning_rate = tf.placeholder(tf.float32, name = 'learning_rate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = []\n",
    "\n",
    "\n",
    "for hidden_count in hidden_count_per_layer:\n",
    "    layer =  tf.nn.rnn_cell.LSTMCell(hidden_count, state_is_tuple=True)\n",
    "    layer_with_dropout = tf.nn.rnn_cell.DropoutWrapper(layer,\n",
    "                                          input_keep_prob=keep_prob,\n",
    "                                          output_keep_prob=1.0)\n",
    "    layers.append(layer)\n",
    "hidden_network = tf.nn.rnn_cell.MultiRNNCell(layers, state_is_tuple=True)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network_state_size(network):\n",
    "    \"\"\"Returns the number of states variables in the network\"\"\"\n",
    "    states = 0\n",
    "    for layer_size in hidden_network.state_size:\n",
    "        states += layer_size[0]\n",
    "        states += layer_size[1]\n",
    "    return states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#based on https://stackoverflow.com/questions/40438107/tensorflow-changing-batch-size-for-rnn-during-text-generation\n",
    "def pack_state_tuple(state_tuple, indent=0):\n",
    "    \"\"\"Returns a (batch_size,network_state_size) matrix of the states in the network\n",
    "        state_tupel = the states obtained from  _ , state = tf.nn.dynamic_rnn(...)\n",
    "    \"\"\"\n",
    "    if isinstance(state_tuple, tf.Tensor) or not hasattr(state_tuple, '__iter__'):\n",
    "        #The LSTMSTateTuple contains 2 Tensors\n",
    "        return state_tuple\n",
    "    else:\n",
    "        l = []\n",
    "        #an unpacked LSTM network is tuple of layer size, each element of the tuple is an LSTMStateTuple\n",
    "        #state_tupel is either the tuple of LSTMStateTuples or it is a LSTMSTateTuple (via recursive call)\n",
    "        for item in state_tuple:\n",
    "            # item is either an LSTMStateTuple (top level call)\n",
    "            # or it is an element of the LSTMStateTuple (first recursive call)\n",
    "            i = pack_state_tuple(item, indent+2)\n",
    "            l.append(i)\n",
    "        \n",
    "        #convert the list of [Tensor(bsz,a), Tensor(bsz,b), ...] Into one long Tensor (bsz, a-b-c-...)\n",
    "        return tf.concat(l,1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_state_tuple(state_tensor, sizes):\n",
    "    \"\"\"The inverse of pack, given a packed_states vector of (batch_size,x) return the LSTMStateTuple \n",
    "    datastructure that can be used as initial state for tf.nn.dynamic_rnn(...) \n",
    "        sizes is the network state size list (cell.state_size)\n",
    "    \"\"\"\n",
    "\n",
    "    def _unpack_state_tuple( sizes_, offset_, indent):\n",
    "        if isinstance(sizes_, tf.Tensor) or not hasattr(sizes_, '__iter__'): \n",
    "            #get a small part (batch size, c or h size of LSTMStateTuple) of the packed state vector of shape (batch size, network states)\n",
    "            return tf.reshape(state_tensor[:, offset_ : (offset_ + sizes_) ], (-1, sizes_)), offset_ + sizes_\n",
    "        else:\n",
    "            result = []\n",
    "            #Top level: sizes is a tuple of size network layers, each element of the tuple is an LSTMStateTuple(c size, h size)\n",
    "            #Recursive call: sizes_ is a LSTMStateTuple\n",
    "            for size in sizes_:\n",
    "                #size is an LSTMStateTuple (toplevel)\n",
    "                #or size is c size or h size (recursive call)\n",
    "                s, offset_ = _unpack_state_tuple( size, offset_, indent+2)\n",
    "                result.append(s)\n",
    "            if isinstance(sizes_, tf.nn.rnn_cell.LSTMStateTuple):\n",
    "                #end of recursive call\n",
    "                #Build a LSTMStateTuple using the c size and h size elements in the result list\n",
    "                return tf.nn.rnn_cell.LSTMStateTuple(*result), offset_\n",
    "            else:\n",
    "                # end of toplevel call\n",
    "                # create a tuple of size network layers. Result is a list of LSTMStateTuple\n",
    "                return tuple(result), offset_\n",
    "    return _unpack_state_tuple( sizes, 0,0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states in network 96\n",
      "(?, 1)\n",
      "(LSTMStateTuple(c=<tf.Tensor 'Reshape:0' shape=(?, 16) dtype=float32>, h=<tf.Tensor 'Reshape_1:0' shape=(?, 16) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'Reshape_2:0' shape=(?, 16) dtype=float32>, h=<tf.Tensor 'Reshape_3:0' shape=(?, 16) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'Reshape_4:0' shape=(?, 16) dtype=float32>, h=<tf.Tensor 'Reshape_5:0' shape=(?, 16) dtype=float32>))\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff 0.0\n"
     ]
    }
   ],
   "source": [
    "#Test pack and unpack\n",
    "\n",
    "#create a placeholder in which we can feed a packed initial_state\n",
    "state_packed_in = tf.placeholder(\n",
    "    tf.float32, \n",
    "    (None,get_network_state_size(hidden_network)), \n",
    "    name=\"state_packed_1\")\n",
    "\n",
    "\n",
    "#Unpack the packed states\n",
    "state_unpacked_out = unpack_state_tuple(state_packed_in,hidden_network.state_size)\n",
    "#Repack the unpacked states\n",
    "state_packed_out = pack_state_tuple(state_unpacked_out)\n",
    "\n",
    "\n",
    "inputs_batch_size = 4\n",
    "a_batch_of_inputs = np.zeros((inputs_batch_size, sequence_length, input_feature_count))\n",
    "\n",
    "#create an initial state vector and fill it with test data\n",
    "an_initial_state = np.zeros((inputs_batch_size*get_network_state_size(hidden_network),1))\n",
    "an_initial_state[:,0] = np.linspace(start=0,stop=an_initial_state.shape[0]-1,num=an_initial_state.shape[0])\n",
    "#reshape it as an packed state \n",
    "an_initial_state_packed = np.reshape(an_initial_state, (inputs_batch_size,get_network_state_size(hidden_network)))\n",
    "\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    up,p = sess.run([state_unpacked_out, state_packed_out],  feed_dict={state_packed_in: an_initial_state_packed})\n",
    "    # compare the original packed states with the ones the were unpacked and then repacked\n",
    "    diff = an_initial_state_packed - p\n",
    "    # should return 0\n",
    "    print(\"diff\",np.sum(np.abs(diff)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states in network 96\n",
      "(128, 96)\n",
      "(?, 96)\n",
      "(LSTMStateTuple(c=<tf.Tensor 'Reshape_12:0' shape=(?, 16) dtype=float32>, h=<tf.Tensor 'Reshape_13:0' shape=(?, 16) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'Reshape_14:0' shape=(?, 16) dtype=float32>, h=<tf.Tensor 'Reshape_15:0' shape=(?, 16) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'Reshape_16:0' shape=(?, 16) dtype=float32>, h=<tf.Tensor 'Reshape_17:0' shape=(?, 16) dtype=float32>))\n"
     ]
    }
   ],
   "source": [
    "sz = get_network_state_size(hidden_network)\n",
    "print(\"states in network\", sz)\n",
    "\n",
    "#pl_batch_size = tf.placeholder(tf.int32, name = 'bsz')\n",
    "\n",
    "\n",
    "#initial_state and zero_state are both packed versions of the network state\n",
    "\n",
    "zero_state = pack_state_tuple(hidden_network.zero_state(batch_size, tf.float32))\n",
    "print(zero_state.shape)\n",
    "\n",
    "initial_state_packed = tf.placeholder_with_default(\n",
    "    zero_state, \n",
    "    (None,sz), \n",
    "    name=\"initial_state\")\n",
    "\n",
    "print(initial_state_packed.shape)\n",
    "state_unpacked = unpack_state_tuple(initial_state_packed,hidden_network.state_size)\n",
    "print(state_unpacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs  (?, 50, 1)\n",
      "packed state (?, 96)\n",
      "outputs before transpose (?, 50, 16)\n",
      "outputs after transpose (50, ?, 16)\n",
      "last output (?, 16)\n",
      "prediction (?, 1)\n",
      "targets (?, 1)\n"
     ]
    }
   ],
   "source": [
    "#out_weights=tf.Variable(tf.random_normal([hidden_count_per_layer[-1],output_feature_count]))\n",
    "#out_bias=tf.Variable(tf.random_normal([output_feature_count]))\n",
    "print(\"inputs \",inputs.shape)\n",
    "outputs, state_unpacked_network_out = tf.nn.dynamic_rnn(hidden_network, inputs, initial_state = state_unpacked, dtype=tf.float32) #, initial_state=rnn_tuple_state, )\n",
    "state_packed_network_out = pack_state_tuple(state_unpacked_network_out)\n",
    "print(\"packed state\", state_packed_network_out.shape)\n",
    "print(\"outputs before transpose\", outputs.shape)\n",
    "outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "print(\"outputs after transpose\", outputs.shape)\n",
    "last_output = tf.gather(outputs, int(outputs.get_shape()[0]) - 1)\n",
    "print(\"last output\", last_output.shape)\n",
    "                                   \n",
    "---------------------------------------------    \n",
    "\n",
    "# Create the cells for the RNN network\n",
    "lstm = tf.nn.rnn_cell.BasicLSTMCell(128)\n",
    "\n",
    "# Get the output and state from dynamic rnn\n",
    "output, state = tf.nn.dynamic_rnn(lstm, sequence, dtype=tf.float32, sequence_length = seqlen)\n",
    "\n",
    "# Convert output to a tessor and reshape it\n",
    "outputs = tf.reshape(tf.pack(output), [-1, lstm.output_size])\n",
    "\n",
    "# Set partions to 2\n",
    "num_partitions = 2\n",
    "\n",
    "# The partitions argument is a tensor which is already fed to a placeholder.\n",
    "# It is a 1-D tensor with the length of batch_size * max_sequence_length.\n",
    "# In this partitions tensor, you need to set the last output idx for each seq to 1 and \n",
    "# others remain 0, so that the result could be separated to two parts,\n",
    "# one is the last outputs and the other one is the non-last outputs.\n",
    "res_out = tf.dynamic_partition(outputs, partitions, num_partitions)\n",
    "\n",
    "# prediction\n",
    "preds = tf.matmul(res_out[1], weights) + bias\n",
    "\n",
    "-------------------------------------------------------   \n",
    "    \n",
    "#out_size = target.get_shape()[2].value\n",
    "predictions = tf.contrib.layers.fully_connected(last_output, output_feature_count, activation_fn=None)\n",
    "print(\"prediction\", predictions.shape)\n",
    "print(\"targets\", targets.shape)\n",
    "#prediction = tf.nn.softmax(logit)\n",
    "#loss = tf.losses.softmax_cross_entropy(target, logit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_sum(tf.squared_difference(predictions, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_indices = np.linspace(\n",
    "    0,\n",
    "    sample_length-sequence_length-prediction_length-1,\n",
    "    sample_length-sequence_length-prediction_length-1, dtype= np.int32)\n",
    "\n",
    "dev_size_perc = 0.20\n",
    "test_size_perc = 0.20\n",
    "\n",
    "dev_size = int(np.floor(start_indices.shape[0] * dev_size_perc))\n",
    "test_size  = int(np.floor(start_indices.shape[0] * test_size_perc))\n",
    "train_size = start_indices.shape[0] - test_size - dev_size\n",
    "train_batch_count = int(np.floor(train_size / batch_size))\n",
    "dev_batch_count = int(np.floor(dev_size / batch_size))\n",
    "test_batch_count = int(np.floor(test_size / batch_size))\n",
    "\n",
    "print(\"dataset size %d\" %(start_indices.shape[0]))\n",
    "print(\"%d Examples (%d batches) in train set\" %(train_size, train_batch_count))\n",
    "print(\"%d Examples (%d batches) in dev set\" %(dev_size,dev_batch_count))\n",
    "print(\"%d Examples (%d batches) in test set\" %(test_size,test_batch_count))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.shuffle (start_indices)\n",
    "train_indices = start_indices[0:int(train_size)]\n",
    "dev_indices= start_indices[int(train_size):int(train_size+dev_size)]\n",
    "test_indices = start_indices[int(train_size+dev_size):int(train_size+dev_size+test_size)]\n",
    "\n",
    "def get_batch(batch_index, indexes, size=batch_size):\n",
    "    batch_start_indexes = indexes[batch_index*size:batch_index*size+size]\n",
    "    batch_inputs = np.zeros((size,sequence_length, input_feature_count))\n",
    "    batch_targets = np.zeros((size,prediction_length))\n",
    "    for i in range(size):\n",
    "        se = batch_start_indexes[i]\n",
    "        part = signal_amp[se:se+sequence_length]\n",
    "        batch_inputs[i,0:sequence_length,0] = part\n",
    "        batch_targets[i,0] = signal_amp[se+sequence_length+1]\n",
    "\n",
    "    return batch_inputs,batch_targets\n",
    "\n",
    "batch_inputs,batch_targets = get_batch(train_batch_count-1,train_indices)\n",
    "print(batch_inputs.shape,batch_targets.shape)\n",
    "\n",
    "example_inputs = batch_inputs[0,:,:]\n",
    "example_targets =  batch_targets[0,:]\n",
    "print(example_inputs.shape)\n",
    "#b_i = 1\n",
    "#b_s = batch_inputs[b_i,0:sequence_length,0]\n",
    "#plotly.offline.iplot({\n",
    "#    \"data\": [Scatter(y=b_s)],\n",
    "#    \"layout\": Layout(title=\"\")\n",
    "#})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle (start_indices)\n",
    "train_indices = start_indices[0:int(train_size)]\n",
    "dev_indices= start_indices[int(train_size):int(train_size+dev_size)]\n",
    "test_indices = start_indices[int(train_size+dev_size):int(train_size+dev_size+test_size)]\n",
    "\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    np.random.shuffle (train_indices)\n",
    "    \n",
    "    batch_inputs,batch_targets = get_batch(0, train_indices)\n",
    "    print(\"batch input shape\", batch_inputs.shape)\n",
    "    #v_outputs, v_state = sess.run([outputs,state], feed_dict={inputs: batch_inputs, targets: batch_targets})\n",
    "    v_predictions, v_state, v_state_packed = sess.run([predictions,state, state_packed], \n",
    "                                      feed_dict={\n",
    "                                          inputs: batch_inputs, \n",
    "                                          targets: batch_targets\n",
    "                                      })\n",
    "    print(v_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle (start_indices)\n",
    "train_indices = start_indices[0:int(train_size)]\n",
    "dev_indices= start_indices[int(train_size):int(train_size+dev_size)]\n",
    "test_indices = start_indices[int(train_size+dev_size):int(train_size+dev_size+test_size)]\n",
    "\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    np.random.shuffle (train_indices)\n",
    "    \n",
    "    batch_inputs,batch_targets = get_batch(0, train_indices)\n",
    "    print(\"batch input shape\", batch_inputs.shape)\n",
    "    #v_outputs, v_state = sess.run([outputs,state], feed_dict={inputs: batch_inputs, targets: batch_targets})\n",
    "    v_predictions, v_state, v_state_packed = sess.run([predictions,state, state_packed], \n",
    "                                      feed_dict={\n",
    "                                          inputs: batch_inputs, \n",
    "                                          targets: batch_targets\n",
    "                                      })\n",
    "    print(v_predictions.shape)\n",
    "    print(v_predictions[0],batch_targets[0])\n",
    "    for i in range(0,120):\n",
    "        v_predictions, v_outputs, v_state, v_state_packed, v_loss, v_opt = sess.run(\n",
    "            [predictions, outputs, state, state_packed, loss, opt], \n",
    "            feed_dict={\n",
    "                learning_rate: 0.02, \n",
    "                inputs: batch_inputs, \n",
    "                targets: batch_targets,\n",
    "                initial_state: v_state_packed\n",
    "            }) #})\n",
    "        print(v_loss,v_predictions[0],batch_targets[0])\n",
    " \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.shuffle (start_indices)\n",
    "train_indices = start_indices[0:int(train_size)]\n",
    "dev_indices= start_indices[int(train_size):int(train_size+dev_size)]\n",
    "test_indices = start_indices[int(train_size+dev_size):int(train_size+dev_size+test_size)]\n",
    "\n",
    "epoch_count = 5\n",
    "\n",
    "loss_results = np.zeros((epoch_count,2))\n",
    "\n",
    "def get_dev_loss():\n",
    "    epoch_dev_loss = 0.0\n",
    "    for devi in range(dev_batch_count):\n",
    "        batch_inputs,batch_targets = get_batch(devi, dev_indices)\n",
    "\n",
    "        batch_dev_loss = sess.run(loss,feed_dict={inputs:batch_inputs,targets:batch_targets})\n",
    "        print(\"  Dev results batch %d, loss %s\" %(  devi, str(batch_dev_loss)))  \n",
    "\n",
    "        epoch_dev_loss += batch_dev_loss\n",
    "        #sys.stdout.write('.')\n",
    "        #sys.stdout.flush()\n",
    "    return epoch_dev_loss / dev_size\n",
    "\n",
    "def generate_graph(graph_size=200):\n",
    "    prime_size = 20\n",
    "    \n",
    "    prime_signal_start_i = 0\n",
    "    \n",
    "    tmp_signal = np.zeros((graph_size,1))\n",
    "    tmp_signal[0:prime_size,0] = signal_amp[prime_signal_start_i:(prime_signal_start_i+prime_size)]\n",
    "    #tmp_signal[0:prime_size,0] = np.random.normal(size=prime_size)*0.6+0.1\n",
    "    tmp_batch = np.zeros((1,sequence_length,1))\n",
    "    \n",
    "    _state_packed = None\n",
    "    for end in range(prime_size, graph_size):\n",
    "        #end = prime_size\n",
    "        tmp_batch[0,:,0] = tmp_signal.take(range((end-sequence_length),end), mode='wrap')\n",
    "        if _state_packed is None:\n",
    "            _state_packed , _prediction = sess.run(\n",
    "                [state_packed, predictions[0,0]], \n",
    "                feed_dict={learning_rate: 0.02, inputs: tmp_batch})\n",
    "        else:\n",
    "            _state_packed , _prediction = sess.run(\n",
    "                [state_packed, predictions[0,0]], \n",
    "                feed_dict={learning_rate: 0.02, initial_state: _state_packed, inputs: tmp_batch})\n",
    "            \n",
    "        #print(_prediction)\n",
    "        tmp_signal[end,0] = _prediction\n",
    "        sys.stdout.write('.')\n",
    "        sys.stdout.flush()\n",
    "    print(\"\")\n",
    "    plotly.offline.iplot({\n",
    "       \"data\": [Scatter(y=tmp_signal[:,0])],\n",
    "       \"layout\": Layout(title=\"\")})\n",
    "\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    epoch_dev_loss = get_dev_loss()    \n",
    "\n",
    "    #print(\"\")            \n",
    "    print(\"Dev results epoch start, loss %s\" %(  str(epoch_dev_loss),))  \n",
    "\n",
    "    for epoch in range(0,epoch_count):\n",
    "        np.random.shuffle (train_indices)\n",
    "        epoch_train_loss = 0.0\n",
    "        for ti in range(train_batch_count):\n",
    "            batch_inputs,batch_targets = get_batch(ti, train_indices)\n",
    "\n",
    "            batch_train_loss, _ = sess.run([loss, opt], feed_dict={learning_rate: 0.002, inputs: batch_inputs, targets: batch_targets})\n",
    "            print(\"  Train results batch %d, loss %s\" %(  ti, str(batch_train_loss)))  \n",
    "            epoch_train_loss += batch_train_loss\n",
    "            #sys.stdout.write('.')\n",
    "            #sys.stdout.flush()\n",
    "        #print(\"\")\n",
    "        epoch_train_loss = epoch_train_loss / train_size\n",
    "        print(\"Training results epoch %d, loss %s\" %( epoch, str(epoch_train_loss)))\n",
    "        epoch_dev_loss = get_dev_loss()    \n",
    "        #print(\"\")            \n",
    "        print(\"Dev results epoch %d, loss %s\" %( epoch, str(epoch_dev_loss)))  \n",
    "        loss_results[epoch,0] = epoch_train_loss\n",
    "        loss_results[epoch,1] = epoch_dev_loss\n",
    "        ti += 1\n",
    "        generate_graph()\n",
    "    generate_graph(graph_size=1000)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
