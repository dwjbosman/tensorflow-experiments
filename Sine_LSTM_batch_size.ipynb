{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly\n",
    "from plotly.graph_objs import Scatter, Layout\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "import IPython.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_length = 50001\n",
    "time_per_sample = 0.01\n",
    "signal_time = np.linspace(num=sample_length,start = 0, stop = sample_length * time_per_sample )\n",
    "signal_amp = np.sin(signal_time*2*np.pi) + np.random.normal(size=sample_length)*0.02\n",
    "    #np.sin(2+signal_time*1.7*np.pi)*0.5 + \\\n",
    "    #np.sin(1+signal_time*2.2*np.pi) + \\\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "type": "scatter",
         "x": [
          0,
          0.010000199999999999,
          0.020000399999999998,
          0.030000599999999995,
          0.040000799999999996,
          0.050001,
          0.06000119999999999,
          0.07000139999999999,
          0.08000159999999999,
          0.09000179999999999,
          0.100002,
          0.1100022,
          0.12000239999999998,
          0.1300026,
          0.14000279999999998,
          0.150003,
          0.16000319999999998,
          0.17000339999999997,
          0.18000359999999999,
          0.19000379999999997,
          0.200004,
          0.21000419999999997,
          0.2200044,
          0.23000459999999998,
          0.24000479999999996,
          0.250005,
          0.2600052,
          0.27000539999999995,
          0.28000559999999997,
          0.2900058,
          0.300006,
          0.31000619999999995,
          0.32000639999999997,
          0.3300066,
          0.34000679999999994,
          0.35000699999999996,
          0.36000719999999997,
          0.3700074,
          0.38000759999999995,
          0.39000779999999996,
          0.400008,
          0.41000819999999993,
          0.42000839999999995,
          0.43000859999999996,
          0.4400088,
          0.45000899999999994,
          0.46000919999999995,
          0.47000939999999997,
          0.4800095999999999,
          0.49000979999999994,
          0.50001,
          0.5100102,
          0.5200104,
          0.5300106,
          0.5400107999999999,
          0.5500109999999999,
          0.5600111999999999,
          0.5700114,
          0.5800116,
          0.5900118,
          0.600012,
          0.6100121999999999,
          0.6200123999999999,
          0.6300125999999999,
          0.6400127999999999,
          0.650013,
          0.6600132,
          0.6700134,
          0.6800135999999999,
          0.6900137999999999,
          0.7000139999999999,
          0.7100141999999999,
          0.7200143999999999,
          0.7300146,
          0.7400148,
          0.7500149999999999,
          0.7600151999999999,
          0.7700153999999999,
          0.7800155999999999,
          0.7900157999999999,
          0.800016,
          0.8100162,
          0.8200163999999999,
          0.8300165999999999,
          0.8400167999999999,
          0.8500169999999999,
          0.8600171999999999,
          0.8700173999999999,
          0.8800176,
          0.8900177999999999,
          0.9000179999999999,
          0.9100181999999999,
          0.9200183999999999,
          0.9300185999999999,
          0.9400187999999999,
          0.950019,
          0.9600191999999999,
          0.9700193999999999,
          0.9800195999999999,
          0.9900197999999999
         ],
         "y": [
          0.008980834471684802,
          0.07397673818298911,
          0.12431480112465122,
          0.14952752993967508,
          0.24939282879074962,
          0.3317073877051379,
          0.35356061304638603,
          0.43449337805762445,
          0.4624468843549403,
          0.5145604681711908,
          0.5507015844475748,
          0.6211723905865782,
          0.7006886201222082,
          0.740930162099742,
          0.7570857986590294,
          0.7992879457282561,
          0.8183401055280364,
          0.8935176786354514,
          0.9216001482279497,
          0.9038560801154214,
          0.9555199392600378,
          0.9983819379186968,
          0.9871832240435015,
          0.9569033393279699,
          1.0014724892079496,
          1.0055618381177445,
          1.0207304224295812,
          1.0073620772576086,
          0.9527855963604622,
          0.9400564098724535,
          0.9443828768444097,
          0.9074179242354367,
          0.8902414488714048,
          0.8776079327663731,
          0.8437405289618026,
          0.8022575096641424,
          0.7594697556764839,
          0.6977620186647,
          0.6575510544105669,
          0.6369270211331006,
          0.6369935082904556,
          0.5294420274870751,
          0.5225243034751444,
          0.435796408257768,
          0.35943517321384433,
          0.3087562237131443,
          0.2695714989363186,
          0.18921967239290396,
          0.11971976136984296,
          0.051741961454096354,
          0.013550762194613276,
          -0.035032357764137996,
          -0.1309962287304393,
          -0.2022872218198296,
          -0.28529473057796645,
          -0.3193459837984497,
          -0.3504984681556402,
          -0.4391682390737725,
          -0.47930183448265623,
          -0.5410662482818334,
          -0.6080771934911942,
          -0.6227775748429822,
          -0.6730113949351433,
          -0.7177388924501494,
          -0.7590116328860576,
          -0.7739179898316673,
          -0.8415471977203403,
          -0.8619347385113817,
          -0.8825632439210033,
          -0.9186377729933557,
          -0.9543563651510173,
          -0.9797179594597882,
          -0.9717665128029458,
          -1.0227390813543655,
          -1.0162138016482536,
          -1.0272135456587668,
          -1.0091647092842295,
          -0.995237281083938,
          -0.9959345887712543,
          -0.9743331233225979,
          -0.9675586934575419,
          -0.9130232349672682,
          -0.8808178535170108,
          -0.8717763716554638,
          -0.8695324553742103,
          -0.8051343484861788,
          -0.7611725437724773,
          -0.7445401996020754,
          -0.6642714318277168,
          -0.6512593927736277,
          -0.5706745344456002,
          -0.5283087585238307,
          -0.46591764807541797,
          -0.4378727918444838,
          -0.36478145799290906,
          -0.28372027210991785,
          -0.2565705754946683,
          -0.22073503098681002,
          -0.09911621793769372,
          -0.05731253800587127
         ]
        }
       ],
       "layout": {
        "title": ""
       }
      },
      "text/html": [
       "<div id=\"c08e57cd-2201-40a1-b616-9fac08f78b7b\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"c08e57cd-2201-40a1-b616-9fac08f78b7b\", [{\"x\": [0.0, 0.010000199999999999, 0.020000399999999998, 0.030000599999999995, 0.040000799999999996, 0.050001, 0.06000119999999999, 0.07000139999999999, 0.08000159999999999, 0.09000179999999999, 0.100002, 0.1100022, 0.12000239999999998, 0.1300026, 0.14000279999999998, 0.150003, 0.16000319999999998, 0.17000339999999997, 0.18000359999999999, 0.19000379999999997, 0.200004, 0.21000419999999997, 0.2200044, 0.23000459999999998, 0.24000479999999996, 0.250005, 0.2600052, 0.27000539999999995, 0.28000559999999997, 0.2900058, 0.300006, 0.31000619999999995, 0.32000639999999997, 0.3300066, 0.34000679999999994, 0.35000699999999996, 0.36000719999999997, 0.3700074, 0.38000759999999995, 0.39000779999999996, 0.400008, 0.41000819999999993, 0.42000839999999995, 0.43000859999999996, 0.4400088, 0.45000899999999994, 0.46000919999999995, 0.47000939999999997, 0.4800095999999999, 0.49000979999999994, 0.50001, 0.5100102, 0.5200104, 0.5300106, 0.5400107999999999, 0.5500109999999999, 0.5600111999999999, 0.5700114, 0.5800116, 0.5900118, 0.600012, 0.6100121999999999, 0.6200123999999999, 0.6300125999999999, 0.6400127999999999, 0.650013, 0.6600132, 0.6700134, 0.6800135999999999, 0.6900137999999999, 0.7000139999999999, 0.7100141999999999, 0.7200143999999999, 0.7300146, 0.7400148, 0.7500149999999999, 0.7600151999999999, 0.7700153999999999, 0.7800155999999999, 0.7900157999999999, 0.800016, 0.8100162, 0.8200163999999999, 0.8300165999999999, 0.8400167999999999, 0.8500169999999999, 0.8600171999999999, 0.8700173999999999, 0.8800176, 0.8900177999999999, 0.9000179999999999, 0.9100181999999999, 0.9200183999999999, 0.9300185999999999, 0.9400187999999999, 0.950019, 0.9600191999999999, 0.9700193999999999, 0.9800195999999999, 0.9900197999999999], \"y\": [0.008980834471684802, 0.07397673818298911, 0.12431480112465122, 0.14952752993967508, 0.24939282879074962, 0.3317073877051379, 0.35356061304638603, 0.43449337805762445, 0.4624468843549403, 0.5145604681711908, 0.5507015844475748, 0.6211723905865782, 0.7006886201222082, 0.740930162099742, 0.7570857986590294, 0.7992879457282561, 0.8183401055280364, 0.8935176786354514, 0.9216001482279497, 0.9038560801154214, 0.9555199392600378, 0.9983819379186968, 0.9871832240435015, 0.9569033393279699, 1.0014724892079496, 1.0055618381177445, 1.0207304224295812, 1.0073620772576086, 0.9527855963604622, 0.9400564098724535, 0.9443828768444097, 0.9074179242354367, 0.8902414488714048, 0.8776079327663731, 0.8437405289618026, 0.8022575096641424, 0.7594697556764839, 0.6977620186647, 0.6575510544105669, 0.6369270211331006, 0.6369935082904556, 0.5294420274870751, 0.5225243034751444, 0.435796408257768, 0.35943517321384433, 0.3087562237131443, 0.2695714989363186, 0.18921967239290396, 0.11971976136984296, 0.051741961454096354, 0.013550762194613276, -0.035032357764137996, -0.1309962287304393, -0.2022872218198296, -0.28529473057796645, -0.3193459837984497, -0.3504984681556402, -0.4391682390737725, -0.47930183448265623, -0.5410662482818334, -0.6080771934911942, -0.6227775748429822, -0.6730113949351433, -0.7177388924501494, -0.7590116328860576, -0.7739179898316673, -0.8415471977203403, -0.8619347385113817, -0.8825632439210033, -0.9186377729933557, -0.9543563651510173, -0.9797179594597882, -0.9717665128029458, -1.0227390813543655, -1.0162138016482536, -1.0272135456587668, -1.0091647092842295, -0.995237281083938, -0.9959345887712543, -0.9743331233225979, -0.9675586934575419, -0.9130232349672682, -0.8808178535170108, -0.8717763716554638, -0.8695324553742103, -0.8051343484861788, -0.7611725437724773, -0.7445401996020754, -0.6642714318277168, -0.6512593927736277, -0.5706745344456002, -0.5283087585238307, -0.46591764807541797, -0.4378727918444838, -0.36478145799290906, -0.28372027210991785, -0.2565705754946683, -0.22073503098681002, -0.09911621793769372, -0.05731253800587127], \"type\": \"scatter\"}], {\"title\": \"\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"c08e57cd-2201-40a1-b616-9fac08f78b7b\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"c08e57cd-2201-40a1-b616-9fac08f78b7b\", [{\"x\": [0.0, 0.010000199999999999, 0.020000399999999998, 0.030000599999999995, 0.040000799999999996, 0.050001, 0.06000119999999999, 0.07000139999999999, 0.08000159999999999, 0.09000179999999999, 0.100002, 0.1100022, 0.12000239999999998, 0.1300026, 0.14000279999999998, 0.150003, 0.16000319999999998, 0.17000339999999997, 0.18000359999999999, 0.19000379999999997, 0.200004, 0.21000419999999997, 0.2200044, 0.23000459999999998, 0.24000479999999996, 0.250005, 0.2600052, 0.27000539999999995, 0.28000559999999997, 0.2900058, 0.300006, 0.31000619999999995, 0.32000639999999997, 0.3300066, 0.34000679999999994, 0.35000699999999996, 0.36000719999999997, 0.3700074, 0.38000759999999995, 0.39000779999999996, 0.400008, 0.41000819999999993, 0.42000839999999995, 0.43000859999999996, 0.4400088, 0.45000899999999994, 0.46000919999999995, 0.47000939999999997, 0.4800095999999999, 0.49000979999999994, 0.50001, 0.5100102, 0.5200104, 0.5300106, 0.5400107999999999, 0.5500109999999999, 0.5600111999999999, 0.5700114, 0.5800116, 0.5900118, 0.600012, 0.6100121999999999, 0.6200123999999999, 0.6300125999999999, 0.6400127999999999, 0.650013, 0.6600132, 0.6700134, 0.6800135999999999, 0.6900137999999999, 0.7000139999999999, 0.7100141999999999, 0.7200143999999999, 0.7300146, 0.7400148, 0.7500149999999999, 0.7600151999999999, 0.7700153999999999, 0.7800155999999999, 0.7900157999999999, 0.800016, 0.8100162, 0.8200163999999999, 0.8300165999999999, 0.8400167999999999, 0.8500169999999999, 0.8600171999999999, 0.8700173999999999, 0.8800176, 0.8900177999999999, 0.9000179999999999, 0.9100181999999999, 0.9200183999999999, 0.9300185999999999, 0.9400187999999999, 0.950019, 0.9600191999999999, 0.9700193999999999, 0.9800195999999999, 0.9900197999999999], \"y\": [0.008980834471684802, 0.07397673818298911, 0.12431480112465122, 0.14952752993967508, 0.24939282879074962, 0.3317073877051379, 0.35356061304638603, 0.43449337805762445, 0.4624468843549403, 0.5145604681711908, 0.5507015844475748, 0.6211723905865782, 0.7006886201222082, 0.740930162099742, 0.7570857986590294, 0.7992879457282561, 0.8183401055280364, 0.8935176786354514, 0.9216001482279497, 0.9038560801154214, 0.9555199392600378, 0.9983819379186968, 0.9871832240435015, 0.9569033393279699, 1.0014724892079496, 1.0055618381177445, 1.0207304224295812, 1.0073620772576086, 0.9527855963604622, 0.9400564098724535, 0.9443828768444097, 0.9074179242354367, 0.8902414488714048, 0.8776079327663731, 0.8437405289618026, 0.8022575096641424, 0.7594697556764839, 0.6977620186647, 0.6575510544105669, 0.6369270211331006, 0.6369935082904556, 0.5294420274870751, 0.5225243034751444, 0.435796408257768, 0.35943517321384433, 0.3087562237131443, 0.2695714989363186, 0.18921967239290396, 0.11971976136984296, 0.051741961454096354, 0.013550762194613276, -0.035032357764137996, -0.1309962287304393, -0.2022872218198296, -0.28529473057796645, -0.3193459837984497, -0.3504984681556402, -0.4391682390737725, -0.47930183448265623, -0.5410662482818334, -0.6080771934911942, -0.6227775748429822, -0.6730113949351433, -0.7177388924501494, -0.7590116328860576, -0.7739179898316673, -0.8415471977203403, -0.8619347385113817, -0.8825632439210033, -0.9186377729933557, -0.9543563651510173, -0.9797179594597882, -0.9717665128029458, -1.0227390813543655, -1.0162138016482536, -1.0272135456587668, -1.0091647092842295, -0.995237281083938, -0.9959345887712543, -0.9743331233225979, -0.9675586934575419, -0.9130232349672682, -0.8808178535170108, -0.8717763716554638, -0.8695324553742103, -0.8051343484861788, -0.7611725437724773, -0.7445401996020754, -0.6642714318277168, -0.6512593927736277, -0.5706745344456002, -0.5283087585238307, -0.46591764807541797, -0.4378727918444838, -0.36478145799290906, -0.28372027210991785, -0.2565705754946683, -0.22073503098681002, -0.09911621793769372, -0.05731253800587127], \"type\": \"scatter\"}], {\"title\": \"\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s_i = 0\n",
    "e_i = s_i + 100\n",
    "x = plotly.offline.iplot({\n",
    "    \"data\": [Scatter(x=signal_time[s_i:e_i],y=signal_amp[s_i:e_i])],\n",
    "    \"layout\": Layout(title=\"\")\n",
    "    \n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 50\n",
    "prediction_length = 1\n",
    "input_feature_count = 1\n",
    "output_feature_count = 1\n",
    "hidden_count_per_layer = [16,16,16]\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, [None, sequence_length, input_feature_count], name = 'inputs')\n",
    "targets = tf.placeholder(tf.float32, [None, output_feature_count], name = 'targets')\n",
    "keep_prob = tf.placeholder(tf.float32, name = 'keep')\n",
    "learning_rate = tf.placeholder(tf.float32, name = 'learning_rate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = []\n",
    "\n",
    "\n",
    "for hidden_count in hidden_count_per_layer:\n",
    "    layer =  tf.nn.rnn_cell.LSTMCell(hidden_count, state_is_tuple=True)\n",
    "    layer_with_dropout = tf.nn.rnn_cell.DropoutWrapper(layer,\n",
    "                                          input_keep_prob=keep_prob,\n",
    "                                          output_keep_prob=1.0)\n",
    "    layers.append(layer)\n",
    "hidden_network = tf.nn.rnn_cell.MultiRNNCell(layers, state_is_tuple=True)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network_state_size(network):\n",
    "    \"\"\"Returns the number of states variables in the network\"\"\"\n",
    "    states = 0\n",
    "    for layer_size in hidden_network.state_size:\n",
    "        states += layer_size[0]\n",
    "        states += layer_size[1]\n",
    "    return states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#based on https://stackoverflow.com/questions/40438107/tensorflow-changing-batch-size-for-rnn-during-text-generation\n",
    "def pack_state_tuple(state_tuple, indent=0):\n",
    "    \"\"\"Returns a (batch_size,network_state_size) matrix of the states in the network\n",
    "        state_tupel = the states obtained from  _ , state = tf.nn.dynamic_rnn(...)\n",
    "    \"\"\"\n",
    "    if isinstance(state_tuple, tf.Tensor) or not hasattr(state_tuple, '__iter__'):\n",
    "        #The LSTMSTateTuple contains 2 Tensors\n",
    "        return state_tuple\n",
    "    else:\n",
    "        l = []\n",
    "        #an unpacked LSTM network is tuple of layer size, each element of the tuple is an LSTMStateTuple\n",
    "        #state_tupel is either the tuple of LSTMStateTuples or it is a LSTMSTateTuple (via recursive call)\n",
    "        for item in state_tuple:\n",
    "            # item is either an LSTMStateTuple (top level call)\n",
    "            # or it is an element of the LSTMStateTuple (first recursive call)\n",
    "            i = pack_state_tuple(item, indent+2)\n",
    "            l.append(i)\n",
    "        \n",
    "        #convert the list of [Tensor(bsz,a), Tensor(bsz,b), ...] Into one long Tensor (bsz, a-b-c-...)\n",
    "        return tf.concat(l,1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_state_tuple(state_tensor, sizes):\n",
    "    \"\"\"The inverse of pack, given a packed_states vector of (batch_size,x) return the LSTMStateTuple \n",
    "    datastructure that can be used as initial state for tf.nn.dynamic_rnn(...) \n",
    "        sizes is the network state size list (cell.state_size)\n",
    "    \"\"\"\n",
    "\n",
    "    def _unpack_state_tuple( sizes_, offset_, indent):\n",
    "        if isinstance(sizes_, tf.Tensor) or not hasattr(sizes_, '__iter__'): \n",
    "            #get a small part (batch size, c or h size of LSTMStateTuple) of the packed state vector of shape (batch size, network states)\n",
    "            return tf.reshape(state_tensor[:, offset_ : (offset_ + sizes_) ], (-1, sizes_)), offset_ + sizes_\n",
    "        else:\n",
    "            result = []\n",
    "            #Top level: sizes is a tuple of size network layers, each element of the tuple is an LSTMStateTuple(c size, h size)\n",
    "            #Recursive call: sizes_ is a LSTMStateTuple\n",
    "            for size in sizes_:\n",
    "                #size is an LSTMStateTuple (toplevel)\n",
    "                #or size is c size or h size (recursive call)\n",
    "                s, offset_ = _unpack_state_tuple( size, offset_, indent+2)\n",
    "                result.append(s)\n",
    "            if isinstance(sizes_, tf.nn.rnn_cell.LSTMStateTuple):\n",
    "                #end of recursive call\n",
    "                #Build a LSTMStateTuple using the c size and h size elements in the result list\n",
    "                return tf.nn.rnn_cell.LSTMStateTuple(*result), offset_\n",
    "            else:\n",
    "                # end of toplevel call\n",
    "                # create a tuple of size network layers. Result is a list of LSTMStateTuple\n",
    "                return tuple(result), offset_\n",
    "    return _unpack_state_tuple( sizes, 0,0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff 0.0\n"
     ]
    }
   ],
   "source": [
    "#Test pack and unpack\n",
    "\n",
    "#create a placeholder in which we can feed a packed initial_state\n",
    "state_packed_in = tf.placeholder(\n",
    "    tf.float32, \n",
    "    (None,get_network_state_size(hidden_network)), \n",
    "    name=\"state_packed_1\")\n",
    "\n",
    "\n",
    "#Unpack the packed states\n",
    "state_unpacked_out = unpack_state_tuple(state_packed_in,hidden_network.state_size)\n",
    "#Repack the unpacked states\n",
    "state_packed_out = pack_state_tuple(state_unpacked_out)\n",
    "\n",
    "\n",
    "inputs_batch_size = 4\n",
    "a_batch_of_inputs = np.zeros((inputs_batch_size, sequence_length, input_feature_count))\n",
    "\n",
    "#create an initial state vector and fill it with test data\n",
    "an_initial_state = np.zeros((inputs_batch_size*get_network_state_size(hidden_network),1))\n",
    "an_initial_state[:,0] = np.linspace(start=0,stop=an_initial_state.shape[0]-1,num=an_initial_state.shape[0])\n",
    "#reshape it as an packed state \n",
    "an_initial_state_packed = np.reshape(an_initial_state, (inputs_batch_size,get_network_state_size(hidden_network)))\n",
    "\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    up,p = sess.run([state_unpacked_out, state_packed_out],  feed_dict={state_packed_in: an_initial_state_packed})\n",
    "    # compare the original packed states with the ones the were unpacked and then repacked\n",
    "    diff = an_initial_state_packed - p\n",
    "    # should return 0\n",
    "    print(\"diff\",np.sum(np.abs(diff)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states in network 96\n",
      "(10, 96)\n",
      "(?, 96)\n",
      "(LSTMStateTuple(c=<tf.Tensor 'Reshape_6:0' shape=(?, 16) dtype=float32>, h=<tf.Tensor 'Reshape_7:0' shape=(?, 16) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'Reshape_8:0' shape=(?, 16) dtype=float32>, h=<tf.Tensor 'Reshape_9:0' shape=(?, 16) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'Reshape_10:0' shape=(?, 16) dtype=float32>, h=<tf.Tensor 'Reshape_11:0' shape=(?, 16) dtype=float32>))\n"
     ]
    }
   ],
   "source": [
    "sz = get_network_state_size(hidden_network)\n",
    "print(\"states in network\", sz)\n",
    "\n",
    "#pl_batch_size = tf.placeholder(tf.int32, name = 'bsz')\n",
    "\n",
    "\n",
    "#initial_state and zero_state are both packed versions of the network state\n",
    "\n",
    "zero_state = pack_state_tuple(hidden_network.zero_state(10, tf.float32))\n",
    "print(zero_state.shape)\n",
    "\n",
    "initial_state_packed = tf.placeholder_with_default(\n",
    "    zero_state, \n",
    "    (None,sz), \n",
    "    name=\"initial_state\")\n",
    "\n",
    "print(initial_state_packed.shape)\n",
    "state_unpacked = unpack_state_tuple(initial_state_packed,hidden_network.state_size)\n",
    "print(state_unpacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs  (?, 50, 1)\n",
      "packed state (?, 96)\n",
      "outputs before transpose (?, 50, 16)\n",
      "outputs after transpose (50, ?, 16)\n",
      "last output (?, 16)\n",
      "prediction (?, 1)\n",
      "targets (?, 1)\n"
     ]
    }
   ],
   "source": [
    "#out_weights=tf.Variable(tf.random_normal([hidden_count_per_layer[-1],output_feature_count]))\n",
    "#out_bias=tf.Variable(tf.random_normal([output_feature_count]))\n",
    "print(\"inputs \",inputs.shape)\n",
    "outputs, state_unpacked_network_out = tf.nn.dynamic_rnn(hidden_network, inputs, initial_state = state_unpacked, dtype=tf.float32) #, initial_state=rnn_tuple_state, )\n",
    "state_packed_network_out = pack_state_tuple(state_unpacked_network_out)\n",
    "print(\"packed state\", state_packed_network_out.shape)\n",
    "print(\"outputs before transpose\", outputs.shape)\n",
    "outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "print(\"outputs after transpose\", outputs.shape)\n",
    "#last_output = tf.gather(outputs, int(outputs.get_shape()[0]) - 1)\n",
    "last_output =  outputs[outputs.shape[0]-1,:,:]\n",
    "print(\"last output\", last_output.shape)\n",
    "                                   \n",
    "#---------------------------------------------    \n",
    "# Create the cells for the RNN network\n",
    "#lstm = tf.nn.rnn_cell.BasicLSTMCell(128)\n",
    "\n",
    "# Get the output and state from dynamic rnn\n",
    "#output, state = tf.nn.dynamic_rnn(lstm, sequence, dtype=tf.float32, sequence_length = seqlen)\n",
    "\n",
    "# Convert output to a tessor and reshape it\n",
    "#outputs = tf.reshape(tf.pack(output), [-1, lstm.output_size])\n",
    "\n",
    "# Set partions to 2\n",
    "#num_partitions = 2\n",
    "\n",
    "# The partitions argument is a tensor which is already fed to a placeholder.\n",
    "# It is a 1-D tensor with the length of batch_size * max_sequence_length.\n",
    "# In this partitions tensor, you need to set the last output idx for each seq to 1 and \n",
    "# others remain 0, so that the result could be separated to two parts,\n",
    "# one is the last outputs and the other one is the non-last outputs.\n",
    "#res_out = tf.dynamic_partition(outputs, partitions, num_partitions)\n",
    "\n",
    "# prediction\n",
    "#preds = tf.matmul(res_out[1], weights) + bias\n",
    "#-------------------------------------------------------   \n",
    "    \n",
    "#out_size = target.get_shape()[2].value\n",
    "predictions = tf.contrib.layers.fully_connected(last_output, output_feature_count, activation_fn=None)\n",
    "print(\"prediction\", predictions.shape)\n",
    "print(\"targets\", targets.shape)\n",
    "#prediction = tf.nn.softmax(logit)\n",
    "#loss = tf.losses.softmax_cross_entropy(target, logit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_sum(tf.squared_difference(predictions, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size 49949\n",
      "29971 Examples (234 batches) in train set\n",
      "9989 Examples (78 batches) in dev set\n",
      "9989 Examples (78 batches) in test set\n"
     ]
    }
   ],
   "source": [
    "start_indices = np.linspace(\n",
    "    0,\n",
    "    sample_length-sequence_length-prediction_length-1,\n",
    "    sample_length-sequence_length-prediction_length-1, dtype= np.int32)\n",
    "\n",
    "dev_size_perc = 0.20\n",
    "test_size_perc = 0.20\n",
    "batch_size = 128 #512 \n",
    "\n",
    "dev_size = int(np.floor(start_indices.shape[0] * dev_size_perc))\n",
    "test_size  = int(np.floor(start_indices.shape[0] * test_size_perc))\n",
    "train_size = start_indices.shape[0] - test_size - dev_size\n",
    "train_batch_count = int(np.floor(train_size / batch_size))\n",
    "dev_batch_count = int(np.floor(dev_size / batch_size))\n",
    "test_batch_count = int(np.floor(test_size / batch_size))\n",
    "\n",
    "print(\"dataset size %d\" %(start_indices.shape[0]))\n",
    "print(\"%d Examples (%d batches) in train set\" %(train_size, train_batch_count))\n",
    "print(\"%d Examples (%d batches) in dev set\" %(dev_size,dev_batch_count))\n",
    "print(\"%d Examples (%d batches) in test set\" %(test_size,test_batch_count))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 50, 1) (128, 1)\n",
      "(50, 1)\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle (start_indices)\n",
    "train_indices = start_indices[0:int(train_size)]\n",
    "dev_indices= start_indices[int(train_size):int(train_size+dev_size)]\n",
    "test_indices = start_indices[int(train_size+dev_size):int(train_size+dev_size+test_size)]\n",
    "\n",
    "def get_batch(batch_index, indexes, size=batch_size):\n",
    "    batch_start_indexes = indexes[batch_index*size:batch_index*size+size]\n",
    "    batch_inputs = np.zeros((size,sequence_length, input_feature_count))\n",
    "    batch_targets = np.zeros((size,prediction_length))\n",
    "    for i in range(size):\n",
    "        se = batch_start_indexes[i]\n",
    "        part = signal_amp[se:se+sequence_length]\n",
    "        batch_inputs[i,0:sequence_length,0] = part\n",
    "        batch_targets[i,0] = signal_amp[se+sequence_length+1]\n",
    "\n",
    "    return batch_inputs,batch_targets\n",
    "\n",
    "batch_inputs,batch_targets = get_batch(train_batch_count-1,train_indices)\n",
    "print(batch_inputs.shape,batch_targets.shape)\n",
    "\n",
    "example_inputs = batch_inputs[0,:,:]\n",
    "example_targets =  batch_targets[0,:]\n",
    "print(example_inputs.shape)\n",
    "#b_i = 1\n",
    "#b_s = batch_inputs[b_i,0:sequence_length,0]\n",
    "#plotly.offline.iplot({\n",
    "#    \"data\": [Scatter(y=b_s)],\n",
    "#    \"layout\": Layout(title=\"\")\n",
    "#})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch input shape (128, 50, 1)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "ConcatOp : Dimensions of inputs should match: shape[0] = [128,1] vs. shape[1] = [10,16]\n\t [[Node: rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/lstm_cell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](rnn/while/TensorArrayReadV3, rnn/while/Switch_3:1, rnn/while/rnn/multi_rnn_cell/cell_2/cell_2/lstm_cell/split/split_dim)]]\n\nCaused by op 'rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/lstm_cell/concat', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-4d6a134b7580>\", line 4, in <module>\n    outputs, state_unpacked_network_out = tf.nn.dynamic_rnn(hidden_network, inputs, initial_state = state_unpacked, dtype=tf.float32) #, initial_state=rnn_tuple_state, )\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 614, in dynamic_rnn\n    dtype=dtype)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 777, in _dynamic_rnn_loop\n    swap_memory=swap_memory)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2816, in while_loop\n    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2640, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2590, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 762, in _time_step\n    (output, new_state) = call_cell()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 748, in <lambda>\n    call_cell = lambda: cell(input_t, state)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 183, in __call__\n    return super(RNNCell, self).__call__(inputs, state)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 575, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 1066, in call\n    cur_inp, new_state = cell(cur_inp, cur_state)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 183, in __call__\n    return super(RNNCell, self).__call__(inputs, state)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 575, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 611, in call\n    lstm_matrix = self._linear1([inputs, m_prev])\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 1189, in __call__\n    res = math_ops.matmul(array_ops.concat(args, 1), self._weights)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 1099, in concat\n    return gen_array_ops._concat_v2(values=values, axis=axis, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 706, in _concat_v2\n    \"ConcatV2\", values=values, axis=axis, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): ConcatOp : Dimensions of inputs should match: shape[0] = [128,1] vs. shape[1] = [10,16]\n\t [[Node: rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/lstm_cell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](rnn/while/TensorArrayReadV3, rnn/while/Switch_3:1, rnn/while/rnn/multi_rnn_cell/cell_2/cell_2/lstm_cell/split/split_dim)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: ConcatOp : Dimensions of inputs should match: shape[0] = [128,1] vs. shape[1] = [10,16]\n\t [[Node: rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/lstm_cell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](rnn/while/TensorArrayReadV3, rnn/while/Switch_3:1, rnn/while/rnn/multi_rnn_cell/cell_2/cell_2/lstm_cell/split/split_dim)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ba1a9b855fa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m                                       feed_dict={\n\u001b[1;32m     18\u001b[0m                                           \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                                           \u001b[0mtargets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                                       })\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: ConcatOp : Dimensions of inputs should match: shape[0] = [128,1] vs. shape[1] = [10,16]\n\t [[Node: rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/lstm_cell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](rnn/while/TensorArrayReadV3, rnn/while/Switch_3:1, rnn/while/rnn/multi_rnn_cell/cell_2/cell_2/lstm_cell/split/split_dim)]]\n\nCaused by op 'rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/lstm_cell/concat', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-4d6a134b7580>\", line 4, in <module>\n    outputs, state_unpacked_network_out = tf.nn.dynamic_rnn(hidden_network, inputs, initial_state = state_unpacked, dtype=tf.float32) #, initial_state=rnn_tuple_state, )\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 614, in dynamic_rnn\n    dtype=dtype)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 777, in _dynamic_rnn_loop\n    swap_memory=swap_memory)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2816, in while_loop\n    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2640, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2590, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 762, in _time_step\n    (output, new_state) = call_cell()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\", line 748, in <lambda>\n    call_cell = lambda: cell(input_t, state)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 183, in __call__\n    return super(RNNCell, self).__call__(inputs, state)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 575, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 1066, in call\n    cur_inp, new_state = cell(cur_inp, cur_state)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 183, in __call__\n    return super(RNNCell, self).__call__(inputs, state)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\", line 575, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 611, in call\n    lstm_matrix = self._linear1([inputs, m_prev])\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 1189, in __call__\n    res = math_ops.matmul(array_ops.concat(args, 1), self._weights)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 1099, in concat\n    return gen_array_ops._concat_v2(values=values, axis=axis, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 706, in _concat_v2\n    \"ConcatV2\", values=values, axis=axis, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): ConcatOp : Dimensions of inputs should match: shape[0] = [128,1] vs. shape[1] = [10,16]\n\t [[Node: rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/lstm_cell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](rnn/while/TensorArrayReadV3, rnn/while/Switch_3:1, rnn/while/rnn/multi_rnn_cell/cell_2/cell_2/lstm_cell/split/split_dim)]]\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle (start_indices)\n",
    "train_indices = start_indices[0:int(train_size)]\n",
    "dev_indices= start_indices[int(train_size):int(train_size+dev_size)]\n",
    "test_indices = start_indices[int(train_size+dev_size):int(train_size+dev_size+test_size)]\n",
    "\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    np.random.shuffle (train_indices)\n",
    "    \n",
    "    batch_inputs,batch_targets = get_batch(0, train_indices)\n",
    "    print(\"batch input shape\", batch_inputs.shape)\n",
    "    #v_outputs, v_state = sess.run([outputs,state], feed_dict={inputs: batch_inputs, targets: batch_targets})\n",
    "    v_predictions, v_state_unpacked = sess.run([predictions, state_unpacked_network_out], \n",
    "                                      feed_dict={\n",
    "                                          inputs: batch_inputs, \n",
    "                                          targets: batch_targets\n",
    "                                      })\n",
    "    print(v_predictions.shape)\n",
    "    print(v_predictions[0],batch_targets[0])\n",
    "    for i in range(0,120):\n",
    "        v_predictions, v_outputs, v_state_unpacked, v_loss, v_opt = sess.run(\n",
    "            [predictions, outputs, state_unpacked_network_out, loss, opt], \n",
    "            feed_dict={\n",
    "                learning_rate: 0.02, \n",
    "                inputs: batch_inputs, \n",
    "                targets: batch_targets,\n",
    "                state_unpacked: v_state_unpacked\n",
    "            }) #})\n",
    "        print(v_loss,v_predictions[0],batch_targets[0])\n",
    " \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.shuffle (start_indices)\n",
    "train_indices = start_indices[0:int(train_size)]\n",
    "dev_indices= start_indices[int(train_size):int(train_size+dev_size)]\n",
    "test_indices = start_indices[int(train_size+dev_size):int(train_size+dev_size+test_size)]\n",
    "\n",
    "epoch_count = 2\n",
    "\n",
    "loss_results = np.zeros((epoch_count,2))\n",
    "\n",
    "def get_dev_loss():\n",
    "    epoch_dev_loss = 0.0\n",
    "    for devi in range(dev_batch_count):\n",
    "        batch_inputs,batch_targets = get_batch(devi, dev_indices)\n",
    "\n",
    "        batch_dev_loss = sess.run(loss,feed_dict={inputs:batch_inputs,targets:batch_targets})\n",
    "        if devi % 20 == 0:\n",
    "            print(\"  Dev results batch %d, loss %s\" %(  devi, str(batch_dev_loss)))  \n",
    "\n",
    "        epoch_dev_loss += batch_dev_loss\n",
    "        #sys.stdout.write('.')\n",
    "        #sys.stdout.flush()\n",
    "    return epoch_dev_loss / dev_size\n",
    "\n",
    "def generate_graph(graph_size=200):\n",
    "    prime_size = 20\n",
    "    \n",
    "    prime_signal_start_i = 0\n",
    "    \n",
    "    tmp_signal = np.zeros((graph_size,1))\n",
    "    tmp_signal[0:prime_size,0] = signal_amp[prime_signal_start_i:(prime_signal_start_i+prime_size)]\n",
    "    #tmp_signal[0:prime_size,0] = np.random.normal(size=prime_size)*0.6+0.1\n",
    "    tmp_batch = np.zeros((1,sequence_length,1))\n",
    "    \n",
    "    _state_unpacked = None\n",
    "    for end in range(prime_size, graph_size):\n",
    "        #end = prime_size\n",
    "        tmp_batch[0,:,0] = tmp_signal.take(range((end-sequence_length),end), mode='wrap')\n",
    "        if _state_unpacked is None:\n",
    "            print(tmp_batch.shape)\n",
    "            print(inputs.shape)\n",
    "            _state_unpacked , _prediction = sess.run(\n",
    "                [state_unpacked_network_out, predictions[0,0]], \n",
    "                feed_dict={learning_rate: 0.02, inputs: tmp_batch})\n",
    "        else:\n",
    "            _state_unpacked , _prediction = sess.run(\n",
    "                [state_unpacked_network_out, predictions[0,0]], \n",
    "                feed_dict={learning_rate: 0.02, state_unpacked: _state_unpacked, inputs: tmp_batch})\n",
    "            \n",
    "        #print(_prediction)\n",
    "        tmp_signal[end,0] = _prediction\n",
    "        sys.stdout.write('.')\n",
    "        sys.stdout.flush()\n",
    "    print(\"\")\n",
    "    plotly.offline.iplot({\n",
    "       \"data\": [Scatter(y=tmp_signal[:,0])],\n",
    "       \"layout\": Layout(title=\"\")})\n",
    "\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    epoch_dev_loss = get_dev_loss()    \n",
    "\n",
    "    #print(\"\")            \n",
    "    print(\"Dev results epoch start, loss %s\" %(  str(epoch_dev_loss),))  \n",
    "\n",
    "    for epoch in range(0,epoch_count):\n",
    "        np.random.shuffle (train_indices)\n",
    "        epoch_train_loss = 0.0\n",
    "        for ti in range(train_batch_count):\n",
    "            batch_inputs,batch_targets = get_batch(ti, train_indices)\n",
    "\n",
    "            batch_train_loss, _ = sess.run([loss, opt], feed_dict={learning_rate: 0.002, inputs: batch_inputs, targets: batch_targets})\n",
    "            if ti % 20 == 0:\n",
    "                print(\"  Train results batch %d, loss %s\" %(  ti, str(batch_train_loss)))  \n",
    "            epoch_train_loss += batch_train_loss\n",
    "            #sys.stdout.write('.')\n",
    "            #sys.stdout.flush()\n",
    "        #print(\"\")\n",
    "        epoch_train_loss = epoch_train_loss / train_size\n",
    "        print(\"Training results epoch %d, loss %s\" %( epoch, str(epoch_train_loss)))\n",
    "        epoch_dev_loss = get_dev_loss()    \n",
    "        #print(\"\")            \n",
    "        print(\"Dev results epoch %d, loss %s\" %( epoch, str(epoch_dev_loss)))  \n",
    "        loss_results[epoch,0] = epoch_train_loss\n",
    "        loss_results[epoch,1] = epoch_dev_loss\n",
    "        ti += 1\n",
    "        generate_graph()\n",
    "    generate_graph(graph_size=1000)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
